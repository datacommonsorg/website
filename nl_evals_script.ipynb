{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shixiao-coder/website/blob/upload-eval-colab/nl_evals_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## See [Evaluation Documentation](https://docs.google.com/document/d/1ajUTCgdGFlInAqdWJB18STaG-TX_uoN1lQFgVPSd8pg/edit?resourcekey=0-czNd7QblghzoQarG5RRMqQ&tab=t.0) for more detailed instruction + background!"
      ],
      "metadata": {
        "id": "NQaUqf8iXFkE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GQAXhJzLGtDh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2043ecc-79ad-45bf-dc1d-f61f9f459f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your browser has been opened to visit:\r\n",
            "\r\n",
            "    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=764086051850-6qr4p6gpi6hn506pt8ejuq83di341hur.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8085%2F&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login&state=zZ5gckakVzm23Kfy4aGO1ijCkMZOdq&access_type=offline&code_challenge=Ahhj_OPge2XIm_WbIxlQiWbHzsXmAgVb-icf_J5-mZo&code_challenge_method=S256\r\n",
            "\n",
            "\n",
            "Credentials saved to file: [/Users/shixiao/.config/gcloud/application_default_credentials.json]\n",
            "\n",
            "These credentials will be used by any library that requests Application Default Credentials (ADC).\n",
            "\n",
            "Quota project \"datcom-website-dev\" was added to ADC which can be used by Google client libraries for billing and quota. Note that some services may still bill the project owning the resource.\n",
            "\n",
            "\n",
            "Updates are available for some Google Cloud CLI components.  To install them,\n",
            "please run:\n",
            "  $ gcloud components update\n",
            "\n",
            "\n",
            "\n",
            "To take a quick anonymous survey, run:\n",
            "  $ gcloud survey\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PdvKLgZCbfK"
      },
      "source": [
        "## (required) Run the Set Up Code\n",
        "\n",
        "**Required: [Create a Colab secret](https://drlee.io/how-to-use-secrets-in-google-colab-for-api-key-protection-a-guide-for-openai-huggingface-and-c1ec9e1277e0#:~:text=Step%2Dby%2DStep%20Guide%20to%20Using%20Colab%20Secrets) called `DC_API_KEY` with your [Data Commons API Key](https://docs.datacommons.org/api/#get-key), by clicking on the key icon in the left navigation bar and \"Add new secret\".**\n",
        "\n",
        "Includes imports, globals, utils, Pydantic model definitions, and df <-> gcs <-> sheets <-> model conversion utils.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Also includes the Scrape API code and Scoring code.\n",
        "\n",
        "### General Inputs\n",
        "This table describes the input required to define the runtime.\n",
        "\n",
        "| Parameter | Type | Default Value | Description |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| `runtime_type` | `string` | `--` | Required. This defines the runtime/environment to use. |\n",
        "| `host_website` | `string` | `--` | Optional. defines the HTTP(s) to use for given runtime_type. If left empty, it is generated from the current runtime_type. |\n",
        "\n",
        "### Local Runtime\n",
        "This part describes the setup required for local runtime.\n",
        "\n",
        "1.   mkdir eval -> cd eval\n",
        "2.   setup requirement.txt\n",
        "3.   python3 -m venv evals_runtime\n",
        "4.   source evals_runtime/bin/activate\n",
        "5.   gcloud auth application-default login --scopes=\"https://www.googleapis.com/auth/drive\",\"https://www.googleapis.com/auth/cloud-platform\"\n",
        "6.   pip3 install -q -r requirements.txt\n",
        "7.   jupyter notebook -NotebookApp.allow_origin='https://colab.research.google.com' --port=8888 --NotebookApp.port_retries=0 --NotebookApp.allow_credentials=True\n",
        "8.   local runtime link with host HTTP\n",
        "\n",
        "requirement.txt packages:\n",
        "\n",
        "    requests\n",
        "    numpy\n",
        "    python-dateutil\n",
        "    pydantic\n",
        "    scikit-learn\n",
        "    pandas\n",
        "    jupyter\n",
        "    notebook\n",
        "    google-auth\n",
        "    fsspec\n",
        "    gcsfs\n",
        "    gspread\n",
        "    google-api-python-client\n",
        "    google-auth-httplib2\n",
        "    google-auth-oauthlib\n",
        "    oauth2client\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utils:\n",
        "\n",
        "* `models_to_gcs_csv`(csv_path:str, models: List[BaseModel])\n",
        "\n",
        "  * Upload list of Pydantic objects to GCS bucket as a CSV.\n",
        "\n",
        "* `gcs_csv_to_sheet`(csv_path, sheet_id)\n",
        "  * Copies csv from GCS to Google Sheets - Nl Goldens Viewer by default\n",
        "\n",
        "* `gcs_csv_to_df`(csv_path, base_class: BaseModel = NlQueryResponse) -> pd.DataFrame:\n",
        "  * Read csv from GCS into Pandas Dataframe, converts dates, places, and variables columns to their respective Pydantic classes\n",
        "\n",
        "* `gcs_csv_to_pydantic_models`(csv_path:str, pydantic_model: BaseModel) -> List[BaseModel]:\n",
        "  * Read csv from GCS into a list of pydantic_model objects\n",
        "\n",
        "* `gcs_csv_to_variable_scrapes`(csv_path: str, pydantic_model: NlQueryResponse = NlGolden) -> List[VariableResponse]:\n",
        "  * Read csv from GCS into a flattened list of VariableResponse objects"
      ],
      "metadata": {
        "id": "2V3uK-vQfSHg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown #### Runtime Related\n",
        "runtime_type = \"local\" # @param [\"prod\",\"dev\",\"local\"]\n",
        "host_website = \"\" # @param {\"type\":\"string\"}\n",
        "\n",
        "if not host_website:\n",
        "  if runtime_type == \"prod\":\n",
        "    host_website = \"https://datacommons.org\"\n",
        "  elif runtime_type == \"dev\":\n",
        "    host_website = \"https://dev.datacommons.org\"\n",
        "  elif runtime_type == \"local\":\n",
        "    host_website = \"http://localhost:8080\"\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "woP1ywexRI9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9XMOxo5CLKs",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title ### Imports\n",
        "import statistics\n",
        "import re\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from pydantic import model_validator\n",
        "from typing import Optional, Any\n",
        "import pandas as pd\n",
        "from enum import Enum, auto\n",
        "from pydantic import BaseModel, ValidationError, field_serializer, ConfigDict\n",
        "import json\n",
        "from typing import Dict, List, Optional\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ch3j7j0c_Nxt",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title ### Utils + Globals\n",
        "\n",
        "from datetime import datetime, date as dt_date\n",
        "\n",
        "GCS_EVAL_DIR = 'gs://datcom-nl-evals/evals'\n",
        "GCS_GOLDENS_DIR = 'gs://datcom-nl-evals/goldens'\n",
        "\n",
        "def now():\n",
        " return datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
        "\n",
        "def today():\n",
        " return dt_date.today().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "def scrapes_path(epoch):\n",
        "  return f'{GCS_EVAL_DIR}/{epoch}/scrape.csv'\n",
        "\n",
        "def goldens_path(epoch):\n",
        "  return f'{GCS_GOLDENS_DIR}/{epoch}.csv'\n",
        "\n",
        "def scores_path(scrape_epoch, score_epoch):\n",
        "  return f'{GCS_EVAL_DIR}/{scrape_epoch}/score_{score_epoch}.csv'\n",
        "\n",
        "def summary_path(scrape_epoch, score_epoch):\n",
        "  return f'{GCS_EVAL_DIR}/{scrape_epoch}/summary_{score_epoch}.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bopTVcaDZsFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d418599e-e802-4dc6-9e50-b0c9241f856c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 10:49:10--  https://raw.githubusercontent.com/clincoln8/datcom-website/refs/heads/nl-pyd/tools/nl/detection_evals/eval_models.py\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8003::154, 2606:50c0:8002::154, 2606:50c0:8000::154, ...\r\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8003::154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3565 (3.5K) [text/plain]\n",
            "Saving to: ‘eval_models.py.5’\n",
            "\n",
            "eval_models.py.5    100%[===================>]   3.48K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 10:49:10 (29.3 MB/s) - ‘eval_models.py.5’ saved [3565/3565]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title Pydantic Models\n",
        "!wget https://raw.githubusercontent.com/clincoln8/datcom-website/refs/heads/nl-pyd/tools/nl/detection_evals/eval_models.py\n",
        "\n",
        "from eval_models import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isfrAkkCyRFx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b4b7100-a5a0-4c73-fb10-c382f4e88f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "# @title ### DF <-> GCS <-> Sheets <-> Pydantic Utils\n",
        "import ast\n",
        "if runtime_type != \"local\":\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "!pip install google-cloud-storage --quiet\n",
        "from google.cloud import storage\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "GCS_GOLDENS_DIR = f\"gs://datcom-nl-evals/goldens\"\n",
        "\n",
        "def models_to_gcs_csv(csv_path:str, models: List[BaseModel]):\n",
        "  '''\n",
        "  This function takes a list of Pydantic models and saves them to a CSV file.\n",
        "\n",
        "  csv_path: The path where the CSV file will be saved.\n",
        "  goldens: A list of NlQueryResponse objects to be converted to CSV.\n",
        "  '''\n",
        "  golden_df = pd.DataFrame([m.model_dump(mode='json') for m in models])\n",
        "  golden_df.to_csv(csv_path, index=False)\n",
        "\n",
        "def df_to_gcs_csv(csv_path, df, pydantic_model):\n",
        "  validated_models = df_to_pydantic_models(df, pydantic_model)\n",
        "  models_to_gcs_csv(csv_path, validated_models)\n",
        "\n",
        "def df_to_pydantic_models(df, pydantic_model: BaseModel) -> List[BaseModel]:\n",
        "  '''This function converts each row of a DF into a class object.\n",
        "\n",
        "  csv_path: The path to the CSV file.\n",
        "  pydantic_model: The Model Class the csv represents.\n",
        "  Returns: A list of NlQueryResponse objects.\n",
        "  '''\n",
        "  return [pydantic_model.model_validate(record) for record in df.to_dict(orient='records')]\n",
        "\n",
        "\n",
        "def df_to_sheet_in_folder(df, sheet_name, scrape_epoch, folder_id='1-yFZ-HrhP1e-JhJ3JRbCjTmeXp78wOwn'):\n",
        "  '''This function reads a DataFrame and uploads its content to a Google Sheet,\n",
        "  handling folder and spreadsheet creation, and sheet naming based on scrape_epoch.\n",
        "\n",
        "  df: The DataFrame to upload.\n",
        "  sheet_name: The desired name for the worksheet.\n",
        "  scrape_epoch: A string representing the scrape epoch, used for spreadsheet naming.\n",
        "  folder_id: The ID of the Google Drive folder to check/create the spreadsheet in.\n",
        "  '''\n",
        "  if runtime_type != \"local\":\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "  import gspread\n",
        "  from gspread.exceptions import SpreadsheetNotFound, WorksheetNotFound\n",
        "\n",
        "  from google.auth import default\n",
        "\n",
        "  creds, _ = default()\n",
        "  gc = gspread.client.Client(auth=creds)\n",
        "\n",
        "  from googleapiclient.discovery import build\n",
        "  drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "  spreadsheet_name = scrape_epoch\n",
        "\n",
        "  # Check if spreadsheet already exists in folder.\n",
        "  results = drive_service.files().list(\n",
        "      q=(\n",
        "        f\"mimeType='application/vnd.google-apps.spreadsheet' and \"\n",
        "        f\"name='{spreadsheet_name}' and \"\n",
        "        f\"'{folder_id}' in parents and \"\n",
        "        f\"trashed=false\"\n",
        "    ),\n",
        "      spaces='drive',\n",
        "      driveId='0AL_se0fAJ2R9Uk9PVA',\n",
        "      includeItemsFromAllDrives=True,\n",
        "      supportsAllDrives=True,\n",
        "      corpora='drive',\n",
        "      fields='files(id, name)'\n",
        "  ).execute()\n",
        "\n",
        "  items = results.get('files', [])\n",
        "  if items:\n",
        "      spreadsheet = gc.open_by_key(items[0]['id'])\n",
        "      logging.info(f\"Spreadsheet '{spreadsheet_name}' found with ID: {spreadsheet.id}\")\n",
        "\n",
        "  else:\n",
        "    # Create a new spreadsheet in Google Drive\n",
        "    spreadsheet = gc.create(spreadsheet_name)\n",
        "    logging.info(f\"Successfully created Google Sheet: {spreadsheet.url}\")\n",
        "\n",
        "    # Place new spreadsheet into the folder\n",
        "    file_id = spreadsheet.id\n",
        "    drive_service.files().update(fileId=file_id,\n",
        "                                  addParents=folder_id,\n",
        "                                  removeParents='root', # Remove from root\n",
        "                                supportsAllDrives = True,\n",
        "                                  fields='id, parents').execute()\n",
        "    logging.info(f\"Moved spreadsheet to folder ID: {folder_id}\")\n",
        "\n",
        "  # Add or overwrite sheet within spreadsheet\n",
        "  try:\n",
        "    worksheet = spreadsheet.worksheet(sheet_name)\n",
        "    logging.info(f\"✅ Found worksheet: '{sheet_name}'. Clearing existing data...\")\n",
        "    worksheet.clear() # Clear all data\n",
        "  except WorksheetNotFound:\n",
        "    logging.info(f\"➕ Worksheet '{sheet_name}' not found. Creating new worksheet...\")\n",
        "    worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=len(df), cols=len(df.columns))\n",
        "\n",
        "  worksheet.update([df.columns.values.tolist()] + df.values.tolist())\n",
        "  logging.info(f\"DataFrame successfully uploaded to sheet '{sheet_name}' in spreadsheet '{spreadsheet.title}'.\")\n",
        "  return f\"{spreadsheet.url}#gid={worksheet.id}\"\n",
        "\n",
        "def gcs_csv_to_sheet(csv_path, gcs_folder):\n",
        "  '''This function reads a CSV file and uploads its content to a Google Sheet.\n",
        "  It requires authentication and uses the gspread library.\n",
        "\n",
        "  csv_path: The path to the CSV file.\n",
        "  gcs_folder: The name of the folder in gcs.\n",
        "  '''\n",
        "  df = pd.read_csv(csv_path)\n",
        "  df.replace(np.nan, None, inplace=True)\n",
        "  sheet_name = csv_path.split('/')[-1].removesuffix(\".csv\")\n",
        "  return df_to_sheet_in_folder(df, sheet_name, gcs_folder)\n",
        "\n",
        "\n",
        "def gcs_csv_to_df(csv_path, pydantic_model: BaseModel = NlQueryResponse) -> pd.DataFrame:\n",
        "  '''\n",
        "  This function reads a CSV file containing golden queries and converts it into\n",
        "  a pandas DataFrame. It uses converters to properly parse the nested data\n",
        "  structures within the 'dates', 'places', and 'variables' columns into their\n",
        "  respective Pydantic models.\n",
        "\n",
        "  csv_path: The path to the CSV file.\n",
        "  base_class: This value determines the appropriate converters to use for each column.\n",
        "  Returns: A pandas DataFrame.\n",
        "  '''\n",
        "\n",
        "  converters = {}\n",
        "  if issubclass(pydantic_model, NlQueryResponse):\n",
        "    converters= {\n",
        "        'dates': lambda dates: [DetectedDate.model_validate(x) for x in ast.literal_eval(dates)],\n",
        "        'places': lambda places: [DetectedPlace.model_validate(x) for x in ast.literal_eval(places)],\n",
        "        'variables': lambda vars: [VariableResponse.model_validate(x) for x in ast.literal_eval(vars)]\n",
        "        }\n",
        "\n",
        "  elif pydantic_model is NlQueryEvalScore:\n",
        "    converters= {\n",
        "        'golden_response': lambda x: NlGolden(**ast.literal_eval(x)),\n",
        "        'scraped_response': lambda x: NlApiScrape(**ast.literal_eval(x)),\n",
        "        'golden_type': GoldenType\n",
        "        }\n",
        "\n",
        "  return pd.read_csv(csv_path, converters=converters)\n",
        "\n",
        "\n",
        "def gcs_csv_to_pydantic_models(csv_path:str, pydantic_model: BaseModel) -> List[BaseModel]:\n",
        "  '''This function reads a CSV file and converts each row into a class object.\n",
        "\n",
        "  csv_path: The path to the CSV file.\n",
        "  pydantic_model: The Model Class the csv represents.\n",
        "  Returns: A list of NlQueryResponse objects.\n",
        "  '''\n",
        "  df = gcs_csv_to_df(csv_path, pydantic_model)\n",
        "  return df_to_pydantic_models(df, pydantic_model)\n",
        "\n",
        "def gcs_csv_to_variable_scrapes(csv_path: str, pydantic_model: NlQueryResponse = NlGolden) -> List[VariableResponse]:\n",
        "  '''This function reads a CSV file, extracts the 'variables' column, and combines all VariableResponse objects from that column into a single list.\n",
        "\n",
        "  csv_path: The path to the CSV file.\n",
        "  pydantic_model: The Model Class the csv represents.\n",
        "  Returns: A list of VariableResponse objects.\n",
        "  '''\n",
        "\n",
        "  df = pd.read_csv(csv_path, usecols=['variables'])\n",
        "  combined_variable_scrapes = [VariableResponse(**var) for vars in df['variables'] for var in ast.literal_eval(vars)]\n",
        "\n",
        "  return combined_variable_scrapes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpGwp4qJTHMn"
      },
      "source": [
        "### Scrape API Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "4gPwxBVElkJ0"
      },
      "outputs": [],
      "source": [
        "# @title ### parse_dates\n",
        "from dataclasses import dataclass\n",
        "from abc import ABC\n",
        "\n",
        "# DateClassificationAttributes taken from\n",
        "# https://github.com/datacommonsorg/website/blob/b92b3f643e2b9116fcda9d0f631991b3c5a88fc7/server/lib/nl/detection/types.py#L338C1-L358C34\n",
        "@dataclass\n",
        "class Date:\n",
        "  \"\"\"Represents a range of two numeric quantities.\"\"\"\n",
        "  prep: str\n",
        "  year: int\n",
        "  month: Optional[int] = 0\n",
        "  year_span: Optional[int] = 0\n",
        "\n",
        "  def __str__(self):\n",
        "    return f'{self.year} - {self.month} | {self.year_span}'\n",
        "\n",
        "@dataclass\n",
        "class DateClassificationAttributes(ABC):\n",
        "  dates: List[Date]\n",
        "  is_single_date: bool\n",
        "  date_trigger_strings: List[str]\n",
        "\n",
        "# Taken from\n",
        "# https://github.com/datacommonsorg/website/blob/b92b3f643e2b9116fcda9d0f631991b3c5a88fc7/server/lib/nl/detection/date.py#L182C1-L201C30\n",
        "def get_date_range_strings(date: Date) -> (str, str):\n",
        "  _LAST_YEARS_PREP = 'last_years'\n",
        "  _START_DATE_PREPS = ['after', 'since', 'from', _LAST_YEARS_PREP]\n",
        "  _END_DATE_PREPS = ['before', 'by', 'until']\n",
        "  _MIN_MONTH = 1\n",
        "  _EXCLUSIVE_DATE_PREPS = ['before', 'after']\n",
        "  _MIN_DOUBLE_DIGIT_MONTH = 10\n",
        "\n",
        "\n",
        "  # Gets the year and month to use as the base date when calculating a date range\n",
        "  def _get_base_year_month(date: Date) -> (int, int):\n",
        "\n",
        "    base_year = date.year\n",
        "    base_month = date.month\n",
        "    # if date range excludes the specified date, need to do some calculations to\n",
        "    # get the base date.\n",
        "    if date.prep in _EXCLUSIVE_DATE_PREPS:\n",
        "      # if specified date is an end date, base date should be earlier than\n",
        "      # specified date\n",
        "      if date.prep in _END_DATE_PREPS:\n",
        "        # if date is monthly, use date that is one month before the specified date\n",
        "        if base_month >= _MIN_MONTH:\n",
        "          base_date = dt_date(base_year, base_month,\n",
        "                                    1) - relativedelta(months=1)\n",
        "          base_year = base_date.year\n",
        "          base_month = base_date.month\n",
        "        # otherwise, use date that is one year before the specified date\n",
        "        else:\n",
        "          base_year = base_year - 1\n",
        "      # if specified date is a start date, base date should be later than\n",
        "      # specified date\n",
        "      elif date.prep in _START_DATE_PREPS:\n",
        "        # if date is monthly, use date that is one month after the specified date\n",
        "        if base_month >= _MIN_MONTH:\n",
        "          base_date = dt_date(base_year, base_month,\n",
        "                                    1) + relativedelta(months=1)\n",
        "          base_year = base_date.year\n",
        "          base_month = base_date.month\n",
        "        # otherwise, use date that is one year after the specified date\n",
        "        else:\n",
        "          base_year = base_year + 1\n",
        "\n",
        "    return base_year, base_month\n",
        "\n",
        "\n",
        "  def _get_month_string(month: int) -> str:\n",
        "    month_string = ''\n",
        "    if month >= _MIN_DOUBLE_DIGIT_MONTH:\n",
        "      month_string = f'-{month}'\n",
        "    elif month >= _MIN_MONTH:\n",
        "      month_string = f'-0{month}'\n",
        "    return month_string\n",
        "\n",
        "  start_date = ''\n",
        "  end_date = ''\n",
        "  if not date or not date.year:\n",
        "    return start_date, end_date\n",
        "  base_year, base_month = _get_base_year_month(date)\n",
        "  year_string = str(base_year)\n",
        "  month_string = _get_month_string(base_month)\n",
        "  base_date = year_string + month_string\n",
        "  if date.prep in _START_DATE_PREPS:\n",
        "    start_date = base_date\n",
        "    if date.year_span > 0:\n",
        "      end_year = base_year + date.year_span\n",
        "      end_date = str(end_year) + month_string\n",
        "  elif date.prep in _END_DATE_PREPS:\n",
        "    end_date = base_date\n",
        "    if date.year_span > 0:\n",
        "      start_year = base_year - date.year_span\n",
        "      start_date = str(start_year) + month_string\n",
        "  return start_date, end_date\n",
        "\n",
        "\n",
        "def parse_dates(dbg_info):\n",
        "  date_classification = dbg_info.get('date_classification', '')\n",
        "\n",
        "  if not date_classification or date_classification == '<None>':\n",
        "    return []\n",
        "\n",
        "  attributes = eval(date_classification)\n",
        "\n",
        "  if not attributes.dates or len(attributes.dates) > 1 :\n",
        "    print('dates list length != 1')\n",
        "    return []\n",
        "\n",
        "  if attributes.is_single_date:\n",
        "    start_date = str(attributes.dates[0].year)\n",
        "    if attributes.dates[0].month:\n",
        "      start_date = f'{start_date}-{attributes.dates[0].month:02d}'\n",
        "    return [DetectedDate(base_date=start_date)]\n",
        "\n",
        "  detected_date = attributes.dates[0]\n",
        "  date_range = get_date_range_strings(detected_date)\n",
        "  if date_range == ('',''):\n",
        "    return empty_dates\n",
        "  start_date = date_range[0] if date_range[0] else today()\n",
        "  end_date = date_range[1] if date_range[1] else today()\n",
        "  return [DetectedDate(base_date=start_date, end_date=end_date)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jUU4fDw50NQP"
      },
      "outputs": [],
      "source": [
        "# @title ### parse_places\n",
        "\n",
        "def parse_places(id, query, dbg_info):\n",
        "  # 1. Identify sub_place_type such as \"County\" or \"State\"\n",
        "  contained_in_classification = dbg_info.get('contained_in_classification', '<None>') # \"<None>\"\" matches the 'default' value returned by debug_info\n",
        "  sub_place_type = contained_in_classification.split('.')[-1] if contained_in_classification != '<None>' else None\n",
        "  if sub_place_type and 'DEFAULT_TYPE' in sub_place_type:\n",
        "    sub_place_type = None\n",
        "\n",
        "  # 2. Identify the detected place dcids\n",
        "  places = []\n",
        "\n",
        "  detection_logs =  dbg_info.get('query_detection_debug_logs', {})\n",
        "  # print(detection_logs)\n",
        "  # print(contained_in_classification)\n",
        "\n",
        "  try:\n",
        "    detected_places = detection_logs.get('place_resolution', {}).get('dc_resolved_places', {})\n",
        "    for detected_place in detected_places:\n",
        "      places.append(DetectedPlace(dcid=detected_place['dcid'], sub_place_type=sub_place_type))\n",
        "  except AttributeError as e:\n",
        "    logging.info(f'[places] no dc_resolved_places; {id} (\"{query}\")')\n",
        "    if sub_place_type:\n",
        "      logging.debug(f'[places] detected only sub_place_type; {id} (\"{query}\")')\n",
        "      places.append(DetectedPlace(dcid='', sub_place_type=sub_place_type))\n",
        "      return places\n",
        "\n",
        "    llm_response = dbg_info.get('llm_response', {})\n",
        "    if llm_response:\n",
        "      # TODO: verify if skipping llm_response when sub_place_type is present is correct\n",
        "      logging.info(f'[places] llm_response:\", )', dbg_info.get('llm_response', {}))\n",
        "\n",
        "      llm_sub_place = llm_response.get('SUB_PLACE_TYPE', '')\n",
        "      if 'DEFAULT_TYPE' in llm_sub_place:\n",
        "        llm_sub_place = None\n",
        "      if llm_sub_place:\n",
        "        places.append(DetectedPlace(dcid='', sub_place_type=llm_sub_place))\n",
        "    else:\n",
        "      logging.debug(f'[places] no place detected; {id} (\"{query}\")')\n",
        "\n",
        "  return places"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92ebmgyde76h",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title ### parse_variables\n",
        "\n",
        "def unfurl_group(topic_dcid, processed_topics):\n",
        "  dcids = []\n",
        "  processed_topic = processed_topics.get(topic_dcid, {})\n",
        "\n",
        "  for peer_group in processed_topic.get('peer_groups', []):\n",
        "    dcids.extend(peer_group[1]) # peer group structure is [peer_group_dcid, [stat_vars]]\n",
        "\n",
        "  for sub_topic in processed_topic.get('sub_topics', []):\n",
        "    dcids.extend(unfurl_group(sub_topic, processed_topics))\n",
        "\n",
        "  dcids.extend(processed_topic.get('svs', []))\n",
        "\n",
        "  return dcids\n",
        "\n",
        "def unfurl_dcids(dcids, processed_topics, id, query):\n",
        "  flat_vars = []\n",
        "  for dcid in dcids:\n",
        "    if dcid.startswith('dc/topic'):\n",
        "      if dcid not in processed_topics:\n",
        "        logging.info(f'[vars] topic not processed: {dcid}; {id} (\"{query}\")')\n",
        "        continue\n",
        "      flat_vars.extend(unfurl_group(dcid, processed_topics))\n",
        "    else:\n",
        "      flat_vars.append(dcid)\n",
        "\n",
        "  return flat_vars\n",
        "\n",
        "def parse_variables(id, query, dbg_info) -> list[VariableResponse]:\n",
        "\n",
        "  sv_matching = dbg_info.get('sv_matching', {})\n",
        "  detection_type = dbg_info.get('detection_type')\n",
        "  query_detection_logs = dbg_info.get('query_detection_debug_logs')\n",
        "  info_logs = dbg_info.get('counters', {}).get('INFO', {})\n",
        "\n",
        "  topics_processed = {}\n",
        "  for topic in info_logs.get('topics_processed', []):\n",
        "    topics_processed.update(topic)\n",
        "\n",
        "\n",
        "  single_sv_best_score = (sv_matching.get('CosineScore', [0]) + [0])[0]\n",
        "\n",
        "  multi_sv_candidate = None\n",
        "  if 'MultiSV' in sv_matching:\n",
        "    for candidate in sv_matching.get('MultiSV', {}).get('Candidates', []):\n",
        "      if candidate['DelimBased'] and len(candidate['Parts']) == 2:\n",
        "        # 0.05 matches the logic in\n",
        "        # https://github.com/datacommonsorg/website/blob/12f305f6525bd5d34d45d564503f827dcad2a9ee/shared/lib/constants.py#L458\n",
        "        if candidate['AggCosineScore'] + 0.05 >= single_sv_best_score:\n",
        "          variables = []\n",
        "          multi_sv_candidate = candidate\n",
        "          for part in multi_sv_candidate['Parts']:\n",
        "            variables.append(VariableResponse(search_label=part['QueryPart'], dcids=unfurl_dcids(part['SV'], topics_processed, id, query)))\n",
        "          return variables\n",
        "\n",
        "\n",
        "  ranking = None\n",
        "  if 'ranking_classification' in dbg_info:\n",
        "    ranking_classification = dbg_info.get('ranking_classification')\n",
        "    if 'HIGH' in ranking_classification:\n",
        "      ranking = Ranking.HIGH\n",
        "    elif 'LOW' in ranking_classification:\n",
        "      ranking = Ranking.LOW\n",
        "\n",
        "\n",
        "  if 'RICH' in dbg_info.get('superlative_classification', ''):\n",
        "    search_label = \"RICH\"\n",
        "    var_dcids = unfurl_dcids(info_logs.get('filtered_svs', [])[0], topics_processed, id, query)\n",
        "\n",
        "  elif 'POOR' in dbg_info.get('superlative_classification', ''):\n",
        "    search_label = \"POOR\"\n",
        "    var_dcids = unfurl_dcids(topics_processed.keys(), topics_processed, id, query)\n",
        "\n",
        "  elif detection_type == 'Hybrid - Heuristic Based' or detection_type=='Heuristic Based':\n",
        "    search_label=query_detection_logs.get('query_transformations', {}).get('sv_detection_query_stop_words_removal', '')\n",
        "    if not search_label:\n",
        "      logging.warning(f'[vars] no sv_detection_query_stop_words_removal, using empty str; {id} (\"{query}\") {query_detection_logs} {sv_matching}')\n",
        "    var_dcids = unfurl_dcids(info_logs.get('filtered_svs', [])[0], topics_processed, id, query)\n",
        "\n",
        "\n",
        "  elif detection_type == 'Hybrid - LLM Fallback' or detection_type=='LLM Based':\n",
        "    variable_strs = query_detection_logs['llm_response']['METRICS']\n",
        "    if len(variable_strs) > 1:\n",
        "      logging.warning('[vars] multiple llm detected statvars')\n",
        "\n",
        "    search_label=variable_strs[0]\n",
        "    var_dcids = unfurl_dcids(info_logs.get('filtered_svs', [])[0], topics_processed, id, query)\n",
        "\n",
        "  else:\n",
        "    logging.warning(f'[vars] different detection mode; {id} (\"{query}\")')\n",
        "\n",
        "\n",
        "  return [VariableResponse(search_label=search_label, dcids=var_dcids, rank=ranking)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title scrape query (main)\n",
        "\n",
        "import requests\n",
        "import logging\n",
        "\n",
        "\n",
        "def scrape_query(id, query, detector_type='hybrid'):\n",
        "  response = None\n",
        "  query_response = None\n",
        "  scrape_date = today()\n",
        "\n",
        "  try:\n",
        "    response = requests.post(f'{host_website}/api/explore/detect-and-fulfill?q={query}&detector={detector_type}', json={}, timeout=None)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "      logging.warning(f'[api]  NL API request failed with status code {response.status_code}; {id} (\"{query}\")')\n",
        "      return NlApiScrape(id=id, query=query, dates=[], places=[], variables=[], api_response_status=ResponseStatus.ERROR, scrape_date=scrape_date)\n",
        "    query_response = response.json()\n",
        "\n",
        "  except json.JSONDecodeError as e:\n",
        "    raise json.JSONDecodeError(f'[api] NL API response is not valid JSON; {id} (\"{query}\"); {e}')\n",
        "\n",
        "  logging.debug(query_response)\n",
        "\n",
        "  dbg_info = query_response.get('debug', {})\n",
        "\n",
        "  if dbg_info.get('blocked', False):\n",
        "    logging.warning(f'[api] NL API blocked request; {id} (\"{query}\")')\n",
        "    return NlApiScrape(id=id, query=query, dates=[], places=[], variables=[], api_blocked=True, scrape_date=scrape_date)\n",
        "\n",
        "  dates = parse_dates(dbg_info)\n",
        "\n",
        "  places = parse_places(id, query, dbg_info)\n",
        "\n",
        "  variables = parse_variables(id, query, dbg_info)\n",
        "\n",
        "  return NlApiScrape(id=id, query=query, dates=dates, places=places, variables=variables, scrape_date=scrape_date)\n",
        "\n",
        "# -- Sanity Test --\n",
        "# logging.basicConfig(\n",
        "#     level=logging.INFO,\n",
        "#     format='%(levelname)s - %(message)s',\n",
        "#     force=True\n",
        "# )\n",
        "# scrape_query(0, 'What is the demographics of students in Sunnyvale')"
      ],
      "metadata": {
        "id": "DLxmIy5V9lld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgO82JDdKAyY"
      },
      "source": [
        "### Scoring Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haRnLniVD-C3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6a5d71e-fa7d-4e5a-801f-85079dbfc902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\r\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dateutil --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cUOxxvvPvgQf"
      },
      "outputs": [],
      "source": [
        "# @title ### score_date\n",
        "\n",
        "def calculate_date_scores(golden_dates: pd.Series, scrape_dates: pd.Series, date_of_scrape: pd.Series) -> pd.Series:\n",
        "  \"\"\"\n",
        "  Calculates date scores. TODO: elaborate\n",
        "  \"\"\"\n",
        "\n",
        "  def score_dates(golden_dates, scraped_dates, date_of_scrape):\n",
        "\n",
        "    def replace_placeholder(date_str):\n",
        "      if date_str == DATE_PLACEHOLDER:\n",
        "        return date_of_scrape\n",
        "\n",
        "      placeholder_pattern = r\"^\\$TODAY([+-])(\\d+)([YM])$\"\n",
        "      placeholders = re.fullmatch(placeholder_pattern, date_str)\n",
        "\n",
        "      if not placeholders:\n",
        "        logging.error(f'Unable to parse date placeholder {date_str}')\n",
        "        return date_str\n",
        "\n",
        "      sign, adjustment, unit = placeholders.groups()\n",
        "      adjustment = int(adjustment)\n",
        "\n",
        "      date_obj = datetime.strptime(date_of_scrape, DATE_OF_SCRAPE_FORMAT)\n",
        "\n",
        "      if unit == 'Y' and sign == '+':\n",
        "          return (date_obj + relativedelta(years=adjustment)).strftime('%Y')\n",
        "      elif unit == 'Y' and sign == '-':\n",
        "        return (date_obj - relativedelta(years=adjustment)).strftime('%Y')\n",
        "      elif unit == 'M' and sign == '+':\n",
        "        return (date_obj + relativedelta(months=adjustment)).strftime('%Y-%m')\n",
        "      elif unit == 'M' and sign == '-':\n",
        "        return (date_obj - relativedelta(months=adjustment)).strftime('%Y-%m')\n",
        "      else:\n",
        "        logging.error(f'Unable to parse date placeholder {date_str}')\n",
        "        return date_str\n",
        "\n",
        "    # If there wasn't a date in the query and the scrape did not hallucinate one,\n",
        "    # return \"empty\" so that this does not positively or negatively impact total\n",
        "    # scoring.\n",
        "    if not golden_dates and not scraped_dates:\n",
        "      return np.nan\n",
        "\n",
        "    # If either golden or scraped is present without the other, then automatic 0.\n",
        "    # (Either we detected dates when goldens say there's none to detect or we\n",
        "    # failed to detect dates when goldens say they are present in the query.)\n",
        "    if bool(golden_dates) ^ bool(scraped_dates):\n",
        "      return 0.0\n",
        "\n",
        "    # Populate any $TODAY based placeholders in the goldens with values\n",
        "    for golden in golden_dates:\n",
        "      if DATE_PLACEHOLDER in golden.base_date:\n",
        "        golden.base_date = replace_placeholder(golden.base_date)\n",
        "\n",
        "      if DATE_PLACEHOLDER in golden.end_date:\n",
        "        golden.end_date = replace_placeholder(golden.end_date)\n",
        "\n",
        "    individual_date_scores = []\n",
        "    for scrape in scraped_dates:\n",
        "      best_score = 0\n",
        "      for golden in golden_dates:\n",
        "\n",
        "        base_date_score = 1.0 if scrape.base_date == golden.base_date else 0.0\n",
        "        end_date_score = 1.0 if scrape.end_date == golden.end_date else 0.0\n",
        "        score = statistics.mean([base_date_score, end_date_score])\n",
        "\n",
        "        if score > best_score:\n",
        "          best_score = score\n",
        "\n",
        "      individual_date_scores.append(best_score)\n",
        "\n",
        "    individual_date_scores.extend([0.0] * abs(len(golden_dates) - len(scraped_dates)))\n",
        "\n",
        "    return statistics.mean(individual_date_scores)\n",
        "\n",
        "  return [score_dates(g, s, d) for g, s, d in zip(golden_dates, scrape_dates, date_of_scrape)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NKE6bB5hy57s"
      },
      "outputs": [],
      "source": [
        "# @title calculate_fbeta (used by places + variables)\n",
        "from sklearn.metrics import fbeta_score\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "def calculate_score(y_true_sets, y_pred_sets, beta=1.0):\n",
        "  def per_sample_fbeta_score(y_true, y_pred, beta=1.0):\n",
        "    \"\"\"\n",
        "    Calculates the F-beta score for each sample in a multilabel setting using\n",
        "    fast, vectorized NumPy operations.\n",
        "\n",
        "    Args:\n",
        "        y_true (np.ndarray): A (n_samples, n_classes) binary matrix of true labels.\n",
        "        y_pred (np.ndarray): A (n_samples, n_classes) binary matrix of predicted labels.\n",
        "        beta (float): The beta value for the F-beta score.\n",
        "\n",
        "    Returns:\n",
        "        A (n_samples,) array of F-beta scores for each sample.\n",
        "    \"\"\"\n",
        "    y_true = y_true.astype(bool)\n",
        "    y_pred = y_pred.astype(bool)\n",
        "\n",
        "    tp = (y_true & y_pred).sum(axis=1)\n",
        "    fp = (y_pred & ~y_true).sum(axis=1)\n",
        "    fn = (y_true & ~y_pred).sum(axis=1)\n",
        "\n",
        "    beta_sq = beta**2\n",
        "\n",
        "    precision = np.divide(tp, tp + fp, out=np.zeros_like(tp, dtype=float), where=(tp + fp) > 0)\n",
        "    recall = np.divide(tp, tp + fn, out=np.zeros_like(tp, dtype=float), where=(tp + fn) > 0)\n",
        "\n",
        "    fbeta = np.divide(\n",
        "        (1 + beta_sq) * precision * recall,\n",
        "        (beta_sq * precision) + recall,\n",
        "        out=np.zeros_like(tp, dtype=float),\n",
        "        where=((beta_sq * precision) + recall) > 0\n",
        "    )\n",
        "\n",
        "    fbeta[(tp + fp + fn) == 0] = 1.0\n",
        "\n",
        "    return np.round(fbeta, decimals=3), np.round(precision, decimals=3), np.round(recall, decimals=3)\n",
        "\n",
        "  mlb = MultiLabelBinarizer()\n",
        "  all_labels = y_true_sets.tolist() + y_pred_sets.tolist()\n",
        "\n",
        "  mlb.fit(all_labels)\n",
        "\n",
        "  y_true_matrix = mlb.transform(y_true_sets)\n",
        "  y_pred_matrix = mlb.transform(y_pred_sets)\n",
        "\n",
        "  return per_sample_fbeta_score(y_true_matrix, y_pred_matrix, beta=beta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "03steDlcvkWj"
      },
      "outputs": [],
      "source": [
        "# @title ### score_place\n",
        "\n",
        "def calculate_place_scores(golden_places_col: pd.Series, scrape_places_col: pd.Series) -> pd.Series:\n",
        "\n",
        "  def get_place_dcid_set(places: list[DetectedPlace]) -> set[str]:\n",
        "    return {place.dcid for place in places}\n",
        "\n",
        "  def get_sub_type_set(places: list[DetectedPlace]) -> set[str]:\n",
        "    labels = set()\n",
        "    for place in places:\n",
        "      if place.sub_place_type:\n",
        "        labels.add(place.sub_place_type)\n",
        "    return labels\n",
        "\n",
        "  def get_place_labels_set(places: list[DetectedPlace]) -> set[str]:\n",
        "    labels = set()\n",
        "    for place in places:\n",
        "      sub_place_type = place.sub_place_type if place.sub_place_type else ''\n",
        "      labels.add(f\"{place.dcid}:{sub_place_type}\")\n",
        "    return labels\n",
        "\n",
        "\n",
        "  # phase 1 - place_dcid scoring; this is to give \"partial credit\" for when a\n",
        "  # parent place is properly detected even when the child place is not\n",
        "  y_true_place_dcids = golden_places_col.apply(get_place_dcid_set)\n",
        "  y_pred_place_dcids = scrape_places_col.apply(get_place_dcid_set)\n",
        "\n",
        "  place_dcids_scores, _, _ = calculate_score(y_true_place_dcids, y_pred_place_dcids, beta=0.8)\n",
        "\n",
        "  # phase 2 - child place type accuracy\n",
        "  y_true_sub_place_types = golden_places_col.apply(get_sub_type_set)\n",
        "  y_pred_sub_place_types = scrape_places_col.apply(get_sub_type_set)\n",
        "\n",
        "  sub_place_type_scores,_,_ = calculate_score(y_true_sub_place_types, y_pred_sub_place_types)\n",
        "\n",
        "  # phase 3 - full place_dcid +/- child type pairs\n",
        "  y_true_full_place = golden_places_col.apply(get_place_labels_set)\n",
        "  y_pred_full_place =  scrape_places_col.apply(get_place_labels_set)\n",
        "\n",
        "  full_place_scores,_,_ = calculate_score(y_true_full_place, y_pred_full_place, beta=0.5)\n",
        "\n",
        "  places_weight = 0.4\n",
        "  child_types_weight = 0.2\n",
        "  full_weight = 0.4\n",
        "\n",
        "  combined_score = pd.Series((places_weight * place_dcids_scores) +\n",
        "                    (child_types_weight * sub_place_type_scores) +\n",
        "                    (full_weight * full_place_scores))\n",
        "\n",
        "  # For cases where there are no places in the goldens, we shouldn't produce a score\n",
        "  # instead, populate with NaN.\n",
        "  do_not_score = (golden_places_col.str.len() == 0) & (scrape_places_col.str.len() == 0)\n",
        "  combined_score.loc[do_not_score] = np.nan\n",
        "\n",
        "  return combined_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "3GqhAp7f7wF5"
      },
      "outputs": [],
      "source": [
        "# @title ### score_variables\n",
        "\n",
        "def calculate_variable_scores(golden_vars_col: pd.Series, scrape_vars_col: pd.Series) -> pd.Series:\n",
        "  \"\"\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def get_var_dcid_set(vars: list[VariableResponse]) -> set[str]:\n",
        "    return {dcid for var in vars for dcid in var.dcids}\n",
        "\n",
        "  # phase 1 - variable dcid scoring\n",
        "\n",
        "  y_true_var_dcids = golden_vars_col.apply(get_var_dcid_set)\n",
        "  y_pred_var_dcids = scrape_vars_col.apply(get_var_dcid_set)\n",
        "\n",
        "  # Use high beta score to favor recall over precision - care more about finding\n",
        "  # right statvars than excluding non-required ones.\n",
        "  var_dcid_fbeta, precision, recall = calculate_score(y_true_var_dcids, y_pred_var_dcids, beta=2)\n",
        "\n",
        "  combined_score = pd.Series(var_dcid_fbeta)\n",
        "  precision = pd.Series(precision)\n",
        "  recall = pd.Series(recall)\n",
        "\n",
        "  # TODO: once all goldens have variables, uncomment the following line and delete the next\n",
        "  # do_not_score = (golden_vars_col.str.len() == 0) & (scrape_vars_col.str.len() == 0)\n",
        "  do_not_score = (golden_vars_col.str.len() == 0)\n",
        "  combined_score.loc[do_not_score] = np.nan\n",
        "  precision.loc[do_not_score] = np.nan\n",
        "  recall.loc[do_not_score] = np.nan\n",
        "\n",
        "  return combined_score, precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv08t8FjJg-p",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Score Epoch\n",
        "\n",
        "import statistics\n",
        "import re\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from pydantic import model_validator\n",
        "from typing import Optional, Any\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "DATE_OF_SCRAPE_FORMAT = '%Y-%m-%d'\n",
        "DATE_PLACEHOLDER = '$TODAY'\n",
        "\n",
        "\n",
        "def calculate_total_scores(date_scores: pd.Series, place_scores: pd.Series, variable_scores: pd.Series) -> pd.Series:\n",
        "\n",
        "    # 1. Define the weights for each component\n",
        "    weights = {\n",
        "        'date': 0.2,\n",
        "        'place': 0.4,\n",
        "        'variable': 0.4\n",
        "    }\n",
        "\n",
        "    # 2. Create a DataFrame from the input Series for easier operations\n",
        "    tmp_df = pd.DataFrame({\n",
        "        'date': date_scores,\n",
        "        'place': place_scores,\n",
        "        'variable': variable_scores\n",
        "    })\n",
        "\n",
        "    # 3. Calculate the Numerator (the weighted sum of scores)\n",
        "    # We replace NaNs with 0 before multiplying by the weight. This ensures that\n",
        "    # missing components contribute nothing to the sum, which is correct.\n",
        "    numerator = (tmp_df['date'].fillna(0) * weights['date']) + \\\n",
        "                (tmp_df['place'].fillna(0) * weights['place']) + \\\n",
        "                (tmp_df['variable'].fillna(0) * weights['variable'])\n",
        "\n",
        "    # 4. Calculate the Dynamic Denominator (the sum of weights for non-NaN scores)\n",
        "    # First, create a boolean DataFrame (True where scores exist)\n",
        "    not_na_df = tmp_df.notna()\n",
        "\n",
        "    # Multiply the boolean DataFrame by the weights. True becomes 1, False becomes 0.\n",
        "    # This gives us the weight of each component IF it had a score, otherwise 0.\n",
        "    applicable_weights_df = not_na_df * pd.Series(weights)\n",
        "\n",
        "    # Sum these weights horizontally (axis=1) to get the total weight for each row\n",
        "    denominator = applicable_weights_df.sum(axis=1)\n",
        "\n",
        "    # 5. Calculate the Final Score\n",
        "    # We use np.divide for safe division, which correctly produces NaN\n",
        "    # if the denominator is 0 (i.e., all scores for a row were NaN).\n",
        "    final_scores = np.divide(numerator, denominator, out=np.full_like(denominator, np.nan), where=denominator!=0)\n",
        "\n",
        "    return pd.Series(final_scores)\n",
        "\n",
        "\n",
        "def compute_scores(goldens_df, scrapes_df):\n",
        "  goldens_df = goldens_df.rename(columns=lambda c: f\"{c}_golden\" if c != 'id' else c)\n",
        "  scrapes_df = scrapes_df.rename(columns=lambda c: f\"{c}_scraped\" if c != 'id' else c)\n",
        "  merged_df = pd.merge(goldens_df, scrapes_df, on='id')\n",
        "\n",
        "  # Drop rows if query is not the same for golden and scraped response\n",
        "  mismatched_query_mask = merged_df['query_golden'] != merged_df['query_scraped']\n",
        "  if mismatched_query_mask.any():\n",
        "    mismatched_ids = merged_df.loc[mismatched_query_mask, 'id'].tolist()\n",
        "    logging.error(f'id collision: same id, different query for {mismatched_ids}; dropping from eval')\n",
        "    merged_df = merged_df[~mismatched_query_mask]\n",
        "\n",
        "  score_df = pd.DataFrame()\n",
        "  score_df['id'] = merged_df['id']\n",
        "  score_df['query'] = merged_df['query_golden']\n",
        "  score_df['golden_type'] = merged_df['golden_type_golden']\n",
        "\n",
        "  # Calculate all scores using vectorized operations; this is more efficient than iterating rows.\n",
        "  score_df['date_score'] = calculate_date_scores(merged_df['dates_golden'], merged_df['dates_scraped'], merged_df['scrape_date_scraped'])\n",
        "  score_df['place_score'] = calculate_place_scores(merged_df['places_golden'], merged_df['places_scraped'])\n",
        "  score_df['variable_score'], score_df['variable_precision'], score_df['variable_recall'] = calculate_variable_scores(merged_df['variables_golden'], merged_df['variables_scraped'])\n",
        "\n",
        "  score_df['total_score'] = calculate_total_scores(score_df['date_score'], score_df['place_score'], score_df['variable_score'])\n",
        "\n",
        "  golden_cols = ['id'] + [col for col in merged_df.columns if col.endswith('_golden')]\n",
        "  merged_goldens_df = merged_df[golden_cols].rename(\n",
        "    columns=lambda c: c.removesuffix('_golden')\n",
        ")\n",
        "  score_df['golden_response'] = df_to_pydantic_models(merged_goldens_df, NlGolden)\n",
        "\n",
        "  scraped_cols = ['id'] + [col for col in merged_df.columns if col.endswith('_scraped')]\n",
        "  merged_srapes_df = merged_df[scraped_cols].rename(\n",
        "    columns=lambda c: c.removesuffix('_scraped')\n",
        ")\n",
        "  score_df['scraped_response'] = df_to_pydantic_models(merged_srapes_df, NlApiScrape)\n",
        "\n",
        "  return score_df\n",
        "\n",
        "def run_epoch_score(golden_epoch, scrape_epoch, score_epoch, description, change_log):\n",
        "  golden_path = goldens_path(golden_epoch)\n",
        "  scrape_path = scrapes_path(scrape_epoch)\n",
        "  score_output_path = scores_path(scrape_epoch, score_epoch)\n",
        "  print(score_output_path)\n",
        "\n",
        "  scrape_df = gcs_csv_to_df(scrape_path, NlApiScrape)\n",
        "  golden_df = gcs_csv_to_df(golden_path, NlGolden)\n",
        "\n",
        "  score_df = compute_scores(golden_df, scrape_df)\n",
        "\n",
        "\n",
        "\n",
        "  df_to_gcs_csv(score_output_path, score_df, NlQueryEvalScore)\n",
        "\n",
        "  summary = pd.DataFrame()\n",
        "  cols = ['total_score', 'date_score', 'place_score', 'variable_score', 'variable_precision', 'variable_recall']\n",
        "  summary['overall'] = score_df[cols].mean().round(3)\n",
        "  summary['stable']  = score_df[score_df['golden_type'] == 'STABLE'][cols].mean().round(3)\n",
        "  summary['aspirational']  = score_df[score_df['golden_type'] == 'ASPIRATIONAL'][cols].mean().round(3)\n",
        "\n",
        "  summary.to_csv('local_summary.csv')\n",
        "\n",
        "  gcs_summary_path = summary_path(scrape_epoch, score_epoch)\n",
        "\n",
        "  metadata = EvalMetadata(golden_epoch = golden_epoch, scrape_epoch=scrape_epoch, score_epoch=score_epoch, description=description, change_log=change_log)\n",
        "\n",
        "  # 6. Append metadata to the CSV\n",
        "  with open('local_summary.csv', 'a') as f: # Use 'a' for append mode\n",
        "      f.write(\",\\n\") # Add a newline for separation\n",
        "      f.write(\",\\n\") # Add a newline for separation\n",
        "      f.write(\"# --- METADATA ---\\n\") # Optional: a clear separator line\n",
        "      for field_name, value in metadata.model_dump().items(): # Use model_dump() for Pydantic v2+\n",
        "          if value is not None: # Only write fields that have a value\n",
        "              # Format as key=value or key,value. Using comma for CSV compatibility\n",
        "              f.write(f\"{field_name},{value}\\n\")\n",
        "\n",
        "  !gsutil cp local_summary.csv {gcs_summary_path} > /dev/null 2>&1\n",
        "\n",
        "  return score_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiPSxOGBxby1"
      },
      "source": [
        "## Scrape and/or Score an epoch\n",
        "\n",
        "### General Inputs\n",
        "This table describes the main input required to define the queryset for the evaluation.\n",
        "\n",
        "* Valid Golden File Names: [gcs link](https://pantheon.corp.google.com/storage/browser/datcom-nl-evals/goldens?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22,%22s%22:%5B(%22i%22:%22displayName%22,%22s%22:%221%22)%5D))&authuser=0&e=13803378&inv=1&invt=Ab3YaQ&mods=-monitoring_api_staging&prefix=&forceOnObjectsSortingFiltering=true)\n",
        "* Previous scrapes: [gcs link](https://pantheon.corp.google.com/storage/browser/datcom-nl-evals/evals?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22,%22s%22:%5B(%22i%22:%22displayName%22,%22s%22:%221%22)%5D))&authuser=0&e=13803378&inv=1&invt=Ab3YaQ&mods=-monitoring_api_staging)\n",
        "\n",
        "| Parameter | Type | Default Value | Description |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| `golden_epoch` | `string` | `--` | Required. The file name of the golden queryset (without extension). This defines the queries to be scraped and serves as the expected values for scoring. |\n",
        "| `scrape_epoch` | `string` | `--` | Required for scoring-only runs, optional when scraping. The unique identifier for a scrape run. If left empty, one is generated from the current date and time. **Caution:** Re-using an existing name will overwrite the previous scrape. |\n",
        "\n",
        "---\n",
        "\n",
        "### Scrape Related Inputs\n",
        "These inputs control the scraping process, which queries the API and saves the responses.\n",
        "\n",
        "| Parameter | Type | Default Value | Description |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| `run_scrape` | `boolean` | `False` | Set to `True` to query the detect-and-fulfill endpoint and save the responses as `NlApiScrape` objects. |\n",
        "| `detector_type` | `string` | `--` | Specifies the detector to use. Options include `\"hybrid\"`, `\"heuristic\"`, and `\"llm\"`. This is not used if `run_scrape` is `False`. |\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Scoring Related Inputs\n",
        "These inputs control the scoring process, which compares the scraped results against the golden set and generates reports.\n",
        "\n",
        "| Parameter | Type | Default Value | Description |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| `run_scoring` | `boolean` | `False` | Set to `True` to score the scraped results against the golden set and generate a score report and summary. |\n",
        "| `eval_description` | `string` | `\"\"` | A brief description of the evaluation run. |\n",
        "| `eval_change_log` | `string` | `\"\"` | A log of any changes relevant to this evaluation run. |\n",
        "| `score_epoch` | `string` | `\"\"` | An optional, unique identifier for the scoring run. If left empty, one will be generated. **Caution:** Re-using an existing name will overwrite previous score reports. |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_Zr4t2OTJkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5e63d6-04d4-4117-be4c-571ff6987b09",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scrape_epoch: 2025-10-09-10-59-19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - [api] NL API blocked request; 794 (\"What is the breakdown of incarceration rates by race in the US\")\n",
            "WARNING - [api] NL API blocked request; 802 (\"Incarceration rates by race in the US\")\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 924 (\"Most dangerous cities to travel to\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['dangerous'], 'RANK': 'HIGH', 'SUB_PLACE_TYPE': 'CITY'}, 'main_place_inferred': None, 'original_query': 'Most dangerous cities to travel to', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Most dangerous cities to travel to', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 935 (\"What percent of people get acquitted from criminal charges\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['percent of people acquitted from criminal charges']}, 'main_place_inferred': None, 'original_query': 'What percent of people get acquitted from criminal charges', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'What percent of people get acquitted from criminal charges', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 932 (\"What is the impact of crime on society\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'What is the impact of crime on society', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'What is the impact of crime on society', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 941 (\"crime rates by city\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['crime rates'], 'SUB_PLACE_TYPE': 'CITY'}, 'main_place_inferred': None, 'original_query': 'crime rates by city', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'crime rates by city', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 970 (\"What does the government spend its money on\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'What does the government spend its money on', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'What does the government spend its money on', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 996 (\"What jobs can I get without a high school degree\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'What jobs can I get without a high school degree', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'What jobs can I get without a high school degree', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 986 (\"How hard is it to get into UC Berkeley\") {'dc_recognize_places': {'Berkeley': ['geoId/0606000', 'geoId/2904906', 'geoId/1705404', 'wikidataId/Q584443']}, 'llm_response': {'PLACES': ['UC Berkeley']}, 'main_place_inferred': None, 'original_query': 'How hard is it to get into UC Berkeley', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'How hard is it to get into UC Berkeley', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1006 (\"How is nuclear fission predicted to affect the energy industry\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'How is nuclear fission predicted to affect the energy industry', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'How is nuclear fission predicted to affect the energy industry', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1002 (\"Where are the best colleges located\") {'dc_recognize_places': {}, 'llm_response': {'RANK': 'HIGH'}, 'main_place_inferred': None, 'original_query': 'Where are the best colleges located', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Where are the best colleges located', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1017 (\"What is the efficiency of different types of energy sources\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['efficiency']}, 'main_place_inferred': None, 'original_query': 'What is the efficiency of different types of energy sources', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'What is the efficiency of different types of energy sources', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1021 (\"When is something considered to be clean energy\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'When is something considered to be clean energy', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'When is something considered to be clean energy', 'SV': [], 'SV_to_Sentences': {}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1032 (\"What is the government doing to protect wildlife in the US\"): generated an exception: 'METRICS'\n",
            "1037 (\"When is monsoon season for countries in Southeast Asia\"): generated an exception: 'METRICS'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1039 (\"Which cities are improving in air quality as time goes on\") {'dc_recognize_places': {}, 'llm_response': {'GROWTH': 'INCREASE', 'METRICS': ['air quality'], 'SUB_PLACE_TYPE': 'CITY'}, 'main_place_inferred': None, 'original_query': 'Which cities are improving in air quality as time goes on', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Which cities are improving in air quality as time goes on', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1040 (\"Which cities have the lowest level of carbon emissions per capita\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['carbon emissions per capita'], 'RANK': 'LOW', 'SUB_PLACE_TYPE': 'CITY'}, 'main_place_inferred': None, 'original_query': 'Which cities have the lowest level of carbon emissions per capita', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Which cities have the lowest level of carbon emissions per capita', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1044 (\"How does farming affect the environment\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'How does farming affect the environment', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'How does farming affect the environment', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1043 (\"How does climate change affect crops\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'How does climate change affect crops', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'How does climate change affect crops', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1048 (\"How much resource does it take to sustain livestock\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['resource']}, 'main_place_inferred': None, 'original_query': 'How much resource does it take to sustain livestock', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'How much resource does it take to sustain livestock', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1053 (\"Prevalence of pesticide use in farm production\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['Prevalence of pesticide use']}, 'main_place_inferred': None, 'original_query': 'Prevalence of pesticide use in farm production', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Prevalence of pesticide use in farm production', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1057 (\"Tell me about GMO\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'Tell me about GMO', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Tell me about GMO', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1052 (\"Impact of livestock on the environment\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'Impact of livestock on the environment', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Impact of livestock on the environment', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1071 (\"How does the immune system work\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'How does the immune system work', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'How does the immune system work', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1077 (\"Is the covid 19 pandemic over\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'Is the covid 19 pandemic over', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Is the covid 19 pandemic over', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1087 (\"What's the difference between the flu and a cold\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'What the difference between the flu and a cold', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'What the difference between the flu and a cold', 'SV': [], 'SV_to_Sentences': {}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1083 (\"Top rated hospitals in my area\"): generated an exception: 'METRICS'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1101 (\"Show me cities with the highest increase in home prices in the last 3 years\") {'dc_recognize_places': {}, 'llm_response': {'GROWTH': 'INCREASE', 'METRICS': ['home prices'], 'RANK': 'HIGH', 'RANKING_FILTER': [{'RANKING_METRIC': 'increase in home prices', 'RANKING_OPERATOR': 'IS_HIGHEST'}], 'SUB_PLACE_TYPE': 'CITY'}, 'main_place_inferred': None, 'original_query': 'Show me cities with the highest increase in home prices in the last 3 years', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Show me cities with the highest increase in home prices in the last 3 years', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1114 (\"Which cities have the most affordable housing\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['affordable housing'], 'PLACES': [], 'RANK': 'HIGH', 'SUB_PLACE_TYPE': 'CITY'}, 'main_place_inferred': None, 'original_query': 'Which cities have the most affordable housing', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Which cities have the most affordable housing', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1125 (\"What does it mean to be carbon neutral\") {'dc_recognize_places': {}, 'llm_response': {}, 'main_place_inferred': None, 'original_query': 'What does it mean to be carbon neutral', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'What does it mean to be carbon neutral', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [api]  NL API request failed with status code 500; 1127 (\"What is the impact of pollution on ocean life in Tulum\")\n",
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 1132 (\"Which cities have switched to using compostable plastics\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['compostable plastics'], 'SUB_PLACE_TYPE': 'CITY'}, 'main_place_inferred': None, 'original_query': 'Which cities have switched to using compostable plastics', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Which cities have switched to using compostable plastics', 'SV': [], 'SV_to_Sentences': {}}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num queries scraped: 494\n",
            "scrape output path: gs://datcom-nl-evals/evals/2025-10-09-10-59-19/scrape.csv\n",
            "score output path: gs://datcom-nl-evals/evals/2025-10-09-10-59-19/score_2025-10-09-11-05-48.csv\n",
            "gs://datcom-nl-evals/evals/2025-10-09-10-59-19/score_2025-10-09-11-05-48.csv\n",
            "------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# @markdown\n",
        "# @markdown ### Inputs:\n",
        "golden_epoch = \"2025-06-23\" # @param {\"type\":\"string\"}\n",
        "scrape_epoch = \"\" # @param {\"type\":\"string\", \"placeholder\":\"Optional for when running scrape, required for a score-only run. Created based on current date+time if empty\"}\n",
        "\n",
        "\n",
        "# @markdown #### Scrape Related Inputs\n",
        "run_scrape = True # @param {\"type\":\"boolean\"}\n",
        "detector_type = \"hybrid\" # @param [\"hybrid\",\"heuristic\",\"llm\"]\n",
        "\n",
        "# @markdown #### Scoring Related Inputs\n",
        "run_scoring = True # @param {\"type\":\"boolean\"}\n",
        "eval_description = \"\" # @param {\"type\":\"string\"}\n",
        "eval_change_log = \"\" # @param {\"type\":\"string\"}\n",
        "score_epoch = \"\" # @param {\"type\":\"string\", \"placeholder\":\"(optional, this will be generated based on current date+time if empty)\"}\n",
        "\n",
        "\n",
        "import concurrent.futures\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.WARNING,\n",
        "    format='%(levelname)s - %(message)s',\n",
        "    force=True\n",
        ")\n",
        "\n",
        "def scrape_queryset(queryset):\n",
        "  results_threading = []\n",
        "\n",
        "  with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
        "\n",
        "      future_to_query = {executor.submit(scrape_query, id, query, detector_type): (id, query) for id, query in queryset.items()}\n",
        "\n",
        "      for future in concurrent.futures.as_completed(future_to_query):\n",
        "          id, query = future_to_query[future]\n",
        "          try:\n",
        "              result = future.result()\n",
        "              results_threading.append(result)\n",
        "          except Exception as exc:\n",
        "              print(f'{id} (\"{query}\"): generated an exception: {exc}')\n",
        "  return results_threading\n",
        "\n",
        "#\n",
        "# ========================== MAIN ==========================\n",
        "#\n",
        "\n",
        "if not run_scrape and not run_scoring:\n",
        "  print('Nothing to do! Select at least one operation to perform')\n",
        "\n",
        "if run_scrape:\n",
        "\n",
        "  goldens_file_path = goldens_path(golden_epoch)\n",
        "  goldens_df = gcs_csv_to_df(goldens_file_path)\n",
        "  queryset = dict(zip(goldens_df['id'].astype(int), goldens_df['query'].astype(str)))\n",
        "\n",
        "  if not scrape_epoch:\n",
        "    scrape_epoch = now()\n",
        "\n",
        "  print(f'scrape_epoch: {scrape_epoch}')\n",
        "\n",
        "  full_scrape = scrape_queryset(queryset)\n",
        "  print(f'num queries scraped: {len(full_scrape)}')\n",
        "\n",
        "\n",
        "  scrapes_gcs = scrapes_path(scrape_epoch)\n",
        "  print(f'scrape output path: {scrapes_gcs}')\n",
        "\n",
        "  # Write to GCS and Sheets\n",
        "  models_to_gcs_csv(scrapes_gcs, full_scrape)\n",
        "  gcs_csv_to_sheet(scrapes_gcs, scrape_epoch)\n",
        "\n",
        "if run_scoring:\n",
        "  if not score_epoch:\n",
        "    score_epoch = now()\n",
        "  print(f'score output path: {scores_path(scrape_epoch, score_epoch)}')\n",
        "\n",
        "  # Conduct Eval\n",
        "  score_df = run_epoch_score(golden_epoch, scrape_epoch, score_epoch, eval_description, eval_change_log)\n",
        "\n",
        "  # Transfer scores from GCS to Sheet\n",
        "  gcs_csv_to_sheet(scores_path(scrape_epoch, score_epoch), scrape_epoch)\n",
        "  summary_url = gcs_csv_to_sheet(summary_path(scrape_epoch, score_epoch), scrape_epoch)\n",
        "\n",
        "  print('------------------------------------------------------------------')\n",
        "  #print('>> View results at', summary_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Misc"
      ],
      "metadata": {
        "id": "0zR7EPFpX4QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy goldens from GCS to sheet!\n",
        "gcs_csv_to_sheet(goldens_path('2025-06-23'), 'goldens')"
      ],
      "metadata": {
        "id": "x7Gtk4QmLt-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IrmNK5yFZbO"
      },
      "source": [
        "## Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s66Mq36Elur3"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBB_tDIgllTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaaf206a-c96f-4e5f-b49e-8624047aab6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".FF........\n",
            "======================================================================\n",
            "FAIL: test_multiple_golden_finds_best_match (__main__.TestCalculateDateScores.test_multiple_golden_finds_best_match)\n",
            "Test that a single scrape finds its best score among multiple goldens.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-870761906.py\", line 74, in test_multiple_golden_finds_best_match\n",
            "    self.assertEqual(result[0], 1.0) # Score is 1.0 because it found the best match\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: 0.5 != 1.0\n",
            "\n",
            "======================================================================\n",
            "FAIL: test_multiple_scraped_averages_scores (__main__.TestCalculateDateScores.test_multiple_scraped_averages_scores)\n",
            "Test that scores from multiple scraped dates are averaged.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-870761906.py\", line 88, in test_multiple_scraped_averages_scores\n",
            "    self.assertEqual(result[0], 0.5) # Average of 1.0 and 0.0\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: 0.3333333333333333 != 0.5\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 11 tests in 0.020s\n",
            "\n",
            "FAILED (failures=2)\n"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "\n",
        "class TestCalculateDateScores(unittest.TestCase):\n",
        "\n",
        "  def setUp(self):\n",
        "      \"\"\"Set up a mock date object structure for use in tests.\"\"\"\n",
        "      # Using SimpleNamespace is a quick way to create mock objects with attributes\n",
        "      self.Date = lambda base, end: DetectedDate(base_date=base, end_date=end)\n",
        "      self.date_of_scrape = '2025-06-11'\n",
        "\n",
        "  def test_no_golden_no_scraped(self):\n",
        "      \"\"\"Test score when both golden and scraped are empty; should be NaN.\"\"\"\n",
        "      golden_series = pd.Series([[]])\n",
        "      scraped_series = pd.Series([[]])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertTrue(np.isnan(result[0]))\n",
        "\n",
        "  def test_no_golden_with_scraped(self):\n",
        "      \"\"\"Test score when scrape hallucinates a date; should be 0.0.\"\"\"\n",
        "      golden_series = pd.Series([[]])\n",
        "      scraped_dates = [self.Date('2025-01-01', '2025-01-02')]\n",
        "      scraped_series = pd.Series([scraped_dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 0.0)\n",
        "\n",
        "  def test_perfect_match(self):\n",
        "      \"\"\"Test score for a perfect match; should be 1.0.\"\"\"\n",
        "      dates = [self.Date('2025-01-01', '2025-01-02')]\n",
        "      golden_series = pd.Series([dates])\n",
        "      scraped_series = pd.Series([dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 1.0)\n",
        "\n",
        "  def test_partial_match_base_date_only(self):\n",
        "      \"\"\"Test score when only the base date matches; should be 0.5.\"\"\"\n",
        "      golden_dates = [self.Date('2025-01-01', '2025-01-02')]\n",
        "      scraped_dates = [self.Date('2025-01-01', '2025-01-03')] # Different end_date\n",
        "      golden_series = pd.Series([golden_dates])\n",
        "      scraped_series = pd.Series([scraped_dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 0.5)\n",
        "\n",
        "  def test_no_match(self):\n",
        "      \"\"\"Test score when dates do not match at all; should be 0.0.\"\"\"\n",
        "      golden_dates = [self.Date('2025-01-01', '2025-01-02')]\n",
        "      scraped_dates = [self.Date('2026-01-01', '2026-01-02')]\n",
        "      golden_series = pd.Series([golden_dates])\n",
        "      scraped_series = pd.Series([scraped_dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 0.0)\n",
        "\n",
        "  def test_multiple_golden_finds_best_match(self):\n",
        "      \"\"\"Test that a single scrape finds its best score among multiple goldens.\"\"\"\n",
        "      golden_dates = [\n",
        "          self.Date('2025-01-01', '2025-01-02'), # No match\n",
        "          self.Date('2025-02-01', '2025-02-02')  # Perfect match\n",
        "      ]\n",
        "      scraped_dates = [self.Date('2025-02-01', '2025-02-02')]\n",
        "      golden_series = pd.Series([golden_dates])\n",
        "      scraped_series = pd.Series([scraped_dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 1.0) # Score is 1.0 because it found the best match\n",
        "\n",
        "  def test_multiple_scraped_averages_scores(self):\n",
        "      \"\"\"Test that scores from multiple scraped dates are averaged.\"\"\"\n",
        "      golden_dates = [self.Date('2025-01-01', '2025-01-02')]\n",
        "      scraped_dates = [\n",
        "          self.Date('2025-01-01', '2025-01-02'), # Perfect match (score = 1.0)\n",
        "          self.Date('2026-01-01', '2026-01-02')  # No match (score = 0.0)\n",
        "      ]\n",
        "      golden_series = pd.Series([golden_dates])\n",
        "      scraped_series = pd.Series([scraped_dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 0.5) # Average of 1.0 and 0.0\n",
        "\n",
        "  def test_golden_with_no_scraped(self):\n",
        "      \"\"\"Test score when scraper finds no dates but should have; should be 0.0.\"\"\"\n",
        "      golden_dates = [self.Date('2025-01-01', '2025-01-02')]\n",
        "      golden_series = pd.Series([golden_dates])\n",
        "      scraped_series = pd.Series([[]])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 0.0)\n",
        "\n",
        "  def test_placeholder_today(self):\n",
        "      \"\"\"Test replacement of the $TODAY placeholder.\"\"\"\n",
        "      golden_dates = [self.Date('$TODAY', '$TODAY')]\n",
        "      scraped_dates = [self.Date('2025-06-11', '2025-06-11')]\n",
        "      golden_series = pd.Series([golden_dates])\n",
        "      scraped_series = pd.Series([scraped_dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 1.0)\n",
        "\n",
        "  def test_placeholder_relative_add_year(self):\n",
        "      \"\"\"Test replacement of a relative date placeholder ($TODAY+1Y).\"\"\"\n",
        "      golden_dates = [self.Date('$TODAY+1Y', '$TODAY-1Y')]\n",
        "      scraped_dates = [self.Date('2026', '2024')]\n",
        "      golden_series = pd.Series([golden_dates])\n",
        "      scraped_series = pd.Series([scraped_dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 1.0)\n",
        "\n",
        "  def test_placeholder_relative_subtract_month(self):\n",
        "      \"\"\"Test replacement of a relative date placeholder ($TODAY-2M).\"\"\"\n",
        "      golden_dates = [self.Date('$TODAY+2M', '$TODAY-2M')]\n",
        "      scraped_dates = [self.Date('2025-08', '2025-04')]\n",
        "      golden_series = pd.Series([golden_dates])\n",
        "      scraped_series = pd.Series([scraped_dates])\n",
        "      scrape_date_series = pd.Series([self.date_of_scrape])\n",
        "\n",
        "      result = calculate_date_scores(golden_series, scraped_series, scrape_date_series)\n",
        "      self.assertEqual(result[0], 1.0)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q64HyK8RetRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b16b095e-6dbc-476d-98bb-1f85f81ec8eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".FF.................\n",
            "======================================================================\n",
            "FAIL: test_multiple_golden_finds_best_match (__main__.TestCalculateDateScores.test_multiple_golden_finds_best_match)\n",
            "Test that a single scrape finds its best score among multiple goldens.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-870761906.py\", line 74, in test_multiple_golden_finds_best_match\n",
            "    self.assertEqual(result[0], 1.0) # Score is 1.0 because it found the best match\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: 0.5 != 1.0\n",
            "\n",
            "======================================================================\n",
            "FAIL: test_multiple_scraped_averages_scores (__main__.TestCalculateDateScores.test_multiple_scraped_averages_scores)\n",
            "Test that scores from multiple scraped dates are averaged.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-870761906.py\", line 88, in test_multiple_scraped_averages_scores\n",
            "    self.assertEqual(result[0], 0.5) # Average of 1.0 and 0.0\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: 0.3333333333333333 != 0.5\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 20 tests in 0.058s\n",
            "\n",
            "FAILED (failures=2)\n"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "\n",
        "class TestPlaceScoreCalculation(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Set up weights and the lambda function to create DetectedPlace objects.\"\"\"\n",
        "        self.parent_weight = 0.4\n",
        "        self.child_weight = 0.2\n",
        "        self.structure_weight = 0.4\n",
        "        # This lambda function makes creating test objects clean and easy\n",
        "        self.Place = lambda dcid='', sub_place_type=None: DetectedPlace(dcid=dcid, sub_place_type=sub_place_type)\n",
        "\n",
        "    def test_perfect_match(self):\n",
        "        \"\"\"Score should be 1.0 for a perfect match.\"\"\"\n",
        "        golden = pd.Series([[self.Place(dcid='geo_ca', sub_place_type='STATE')]])\n",
        "        scraped = pd.Series([[self.Place(dcid='geo_ca', sub_place_type='STATE')]])\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "        self.assertAlmostEqual(result[0], 1.0)\n",
        "\n",
        "    def test_partial_credit_parent_only(self):\n",
        "        \"\"\"Score should be parent_weight if only the parent matches.\"\"\"\n",
        "        golden = pd.Series([[self.Place(dcid='geo_ca', sub_place_type='STATE')]])\n",
        "        scraped = pd.Series([[self.Place(dcid='geo_ca')]]) # Missing sub_place_type\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "        self.assertAlmostEqual(result[0], self.parent_weight)\n",
        "\n",
        "    def test_partial_credit_child_only(self):\n",
        "        \"\"\"Score should be child_weight if only the child matches.\"\"\"\n",
        "        golden = pd.Series([[self.Place(dcid='geo_ca', sub_place_type='STATE')]])\n",
        "        scraped = pd.Series([[self.Place(sub_place_type='STATE')]]) # Missing dcid\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "        self.assertAlmostEqual(result[0], self.child_weight)\n",
        "\n",
        "    def test_partial_credit_wrong_parent_correct_child(self):\n",
        "        \"\"\"Score should be child_weight if child is right but parent is wrong.\"\"\"\n",
        "        golden = pd.Series([[self.Place(dcid='geo_ca', sub_place_type='STATE')]])\n",
        "        scraped = pd.Series([[self.Place(dcid='geo_us', sub_place_type='STATE')]])\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "        self.assertAlmostEqual(result[0], self.child_weight)\n",
        "\n",
        "    def test_total_miss(self):\n",
        "        \"\"\"Score should be 0.0 for a complete mismatch.\"\"\"\n",
        "        golden = pd.Series([[self.Place(dcid='geo_ca', sub_place_type='STATE')]])\n",
        "        scraped = pd.Series([[self.Place(dcid='geo_us', sub_place_type='COUNTY')]])\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "        self.assertAlmostEqual(result[0], 0.0)\n",
        "\n",
        "    def test_not_applicable_case(self):\n",
        "        \"\"\"Score should be NaN if both golden and scraped are empty.\"\"\"\n",
        "        golden = pd.Series([[]])\n",
        "        scraped = pd.Series([[]])\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "        self.assertTrue(np.isnan(result[0]))\n",
        "\n",
        "    def test_golden_expected_scrape_empty(self):\n",
        "        \"\"\"Score should be 0.0 if scrape misses an expected place.\"\"\"\n",
        "        golden = pd.Series([[self.Place(dcid='geo_ca', sub_place_type='STATE')]])\n",
        "        scraped = pd.Series([[]])\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "        self.assertAlmostEqual(result[0], 0.0)\n",
        "\n",
        "    def test_scrape_hallucinated_golden_empty(self):\n",
        "        \"\"\"Score should be 0.0 if scrape finds a place that wasn't expected.\"\"\"\n",
        "        golden = pd.Series([[]])\n",
        "        scraped = pd.Series([[self.Place(dcid='geo_ca', sub_place_type='STATE')]])\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "        self.assertAlmostEqual(result[0], 0.0)\n",
        "\n",
        "    def test_multiple_labels_and_rows(self):\n",
        "        \"\"\"Test with a multi-row DataFrame and multiple labels per row.\"\"\"\n",
        "        golden = pd.Series([\n",
        "            [self.Place('geo_ca', 'STATE'), self.Place('geo_us', 'COUNTRY')], # Row 0\n",
        "            [self.Place('geo_de')]                                           # Row 1\n",
        "        ])\n",
        "        scraped = pd.Series([\n",
        "            [self.Place('geo_ca', 'STATE'), self.Place('geo_us')], # Row 0: Partial match\n",
        "            [self.Place('geo_de', 'STATE')]                      # Row 1: Partial match\n",
        "        ])\n",
        "\n",
        "        result = calculate_place_scores(golden, scraped)\n",
        "\n",
        "        # Expected Score for Row 0\n",
        "        parent_score_0 = 1.0; child_score_0 = 0.666666; structure_score_0 = 0.5\n",
        "        expected_score_0 = (self.parent_weight * parent_score_0) + (self.child_weight * child_score_0) + (self.structure_weight * structure_score_0)\n",
        "\n",
        "        # Expected Score for Row 1\n",
        "        parent_score_1 = 1.0; child_score_1 = 0.0; structure_score_1 = 0.0\n",
        "        expected_score_1 = (self.parent_weight * parent_score_1) + (self.child_weight * child_score_1) + (self.structure_weight * structure_score_1)\n",
        "\n",
        "        self.assertEqual(len(result), 2)\n",
        "        self.assertAlmostEqual(result[0], expected_score_0, places=3)\n",
        "        self.assertAlmostEqual(result[1], expected_score_1, places=3)\n",
        "\n",
        "\n",
        "# --- Run the tests in the notebook ---\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPGZSHCcKhIn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "086845dd-a5e2-4177-ee20-878e91887d6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".FF......................\n",
            "======================================================================\n",
            "FAIL: test_multiple_golden_finds_best_match (__main__.TestCalculateDateScores.test_multiple_golden_finds_best_match)\n",
            "Test that a single scrape finds its best score among multiple goldens.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-870761906.py\", line 74, in test_multiple_golden_finds_best_match\n",
            "    self.assertEqual(result[0], 1.0) # Score is 1.0 because it found the best match\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: 0.5 != 1.0\n",
            "\n",
            "======================================================================\n",
            "FAIL: test_multiple_scraped_averages_scores (__main__.TestCalculateDateScores.test_multiple_scraped_averages_scores)\n",
            "Test that scores from multiple scraped dates are averaged.\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-870761906.py\", line 88, in test_multiple_scraped_averages_scores\n",
            "    self.assertEqual(result[0], 0.5) # Average of 1.0 and 0.0\n",
            "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AssertionError: 0.3333333333333333 != 0.5\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 25 tests in 0.084s\n",
            "\n",
            "FAILED (failures=2)\n"
          ]
        }
      ],
      "source": [
        "import unittest\n",
        "\n",
        "class TestTotalScoreCalculation(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Define weights in ONE place. All tests will use this.\"\"\"\n",
        "        self.weights = {\n",
        "            'date': 0.2,\n",
        "            'place': 0.4,\n",
        "            'variable': 0.4\n",
        "        }\n",
        "\n",
        "    def test_all_scores_present(self):\n",
        "        \"\"\"Test calculation when all component scores are valid.\"\"\"\n",
        "        scores_dict = {'date': 1.0, 'place': 0.8, 'variable': 0.9}\n",
        "\n",
        "        # The test now calculates the expected value automatically\n",
        "        expected_score = 0\n",
        "        for component, weight in self.weights.items():\n",
        "            expected_score += scores_dict[component] * weight\n",
        "\n",
        "        result = calculate_total_scores(\n",
        "            pd.Series([scores_dict['date']]),\n",
        "            pd.Series([scores_dict['place']]),\n",
        "            pd.Series([scores_dict['variable']]),\n",
        "        )\n",
        "        self.assertAlmostEqual(result[0], expected_score)\n",
        "\n",
        "    def test_one_score_is_nan(self):\n",
        "        \"\"\"Test re-normalization when one score is NaN.\"\"\"\n",
        "        scores_dict = {'date': np.nan, 'place': 0.8, 'variable': 0.9}\n",
        "\n",
        "        expected_score, total_weight = 0, 0\n",
        "        for component, score in scores_dict.items():\n",
        "          if pd.notna(score):\n",
        "              expected_score += score * self.weights[component]\n",
        "              total_weight += self.weights[component]\n",
        "        expected_score /= total_weight\n",
        "\n",
        "        result = calculate_total_scores(\n",
        "            pd.Series([scores_dict['date']]),\n",
        "            pd.Series([scores_dict['place']]),\n",
        "            pd.Series([scores_dict['variable']]),\n",
        "        )\n",
        "        self.assertAlmostEqual(result[0], expected_score)\n",
        "\n",
        "    def test_two_scores_are_nan(self):\n",
        "        \"\"\"Test calculation when only one score is valid.\"\"\"\n",
        "        scores_dict = {'date': np.nan, 'place': 0.8, 'variable': np.nan}\n",
        "\n",
        "        expected_score, total_weight = 0, 0\n",
        "        for component, score in scores_dict.items():\n",
        "          if pd.notna(score):\n",
        "              expected_score += score * self.weights[component]\n",
        "              total_weight += self.weights[component]\n",
        "        expected_score /= total_weight\n",
        "\n",
        "        result = calculate_total_scores(\n",
        "            pd.Series([scores_dict['date']]),\n",
        "            pd.Series([scores_dict['place']]),\n",
        "            pd.Series([scores_dict['variable']]),\n",
        "        )\n",
        "        self.assertAlmostEqual(result[0], expected_score)\n",
        "\n",
        "    def test_all_scores_are_nan(self):\n",
        "        \"\"\"Test that the result is NaN when all inputs are NaN.\"\"\"\n",
        "        scores_dict = {'date': np.nan, 'place': np.nan, 'variable': np.nan}\n",
        "\n",
        "        result = calculate_total_scores(\n",
        "            pd.Series([scores_dict['date']]),\n",
        "            pd.Series([scores_dict['place']]),\n",
        "            pd.Series([scores_dict['variable']]),\n",
        "        )\n",
        "        self.assertTrue(np.isnan(result[0]))\n",
        "\n",
        "    def test_vectorized_multi_row(self):\n",
        "        \"\"\"Test a multi-row Series to ensure vectorization works correctly.\"\"\"\n",
        "        # Define scores for multiple rows\n",
        "        scores_data = [\n",
        "            {'date': 1.0, 'place': 0.8, 'variable': 0.9},    # Row 0\n",
        "            {'date': np.nan, 'place': 0.8, 'variable': 0.9}, # Row 1\n",
        "            {'date': 0.5, 'place': 0.7, 'variable': np.nan},  # Row 2\n",
        "            {'date': np.nan, 'place': np.nan, 'variable': np.nan} # Row 3\n",
        "        ]\n",
        "\n",
        "        # Create the input Series\n",
        "        date_s = pd.Series([d['date'] for d in scores_data])\n",
        "        place_s = pd.Series([d['place'] for d in scores_data])\n",
        "        variable_s = pd.Series([d['variable'] for d in scores_data])\n",
        "\n",
        "        # Calculate all expected scores in a loop using the simple oracle\n",
        "        def calculate_weighted_average_for_test(scores, weights):\n",
        "          total_score, total_weight = 0, 0\n",
        "          for component, score in scores.items():\n",
        "            if pd.notna(score):\n",
        "                total_score += score * weights[component]\n",
        "                total_weight += weights[component]\n",
        "          if not total_weight:\n",
        "            return np.nan\n",
        "          return total_score / total_weight\n",
        "\n",
        "        expected_scores = [calculate_weighted_average_for_test(d, self.weights) for d in scores_data]\n",
        "\n",
        "        # Calculate all actual scores at once using the vectorized function\n",
        "        result = calculate_total_scores(date_s, place_s, variable_s)\n",
        "\n",
        "        # Assert each result matches its expectation\n",
        "        self.assertEqual(len(result), 4)\n",
        "        self.assertAlmostEqual(result[0], expected_scores[0])\n",
        "        self.assertAlmostEqual(result[1], expected_scores[1])\n",
        "        self.assertAlmostEqual(result[2], expected_scores[2])\n",
        "        self.assertTrue(np.isnan(result[3]))\n",
        "\n",
        "# --- Run the tests in the notebook ---\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8kgB--EPhgp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Idp088lPo0w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "ac5736af-ce96-4375-8f7a-f7d83ee1a8c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      0\n",
              "      ..\n",
              "492    0\n",
              "493    1\n",
              "494    0\n",
              "495    0\n",
              "496    1\n",
              "Name: variables, Length: 497, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variables</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>497 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df = gcs_csv_to_df(goldens_path(golden_epoch), NlGolden)\n",
        "df['variables'].str.len()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fVVnDkcxUCH"
      },
      "source": [
        "### sample set for scraping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flDiWZzx2hDd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "597984fc-7833-4909-ffe2-cf2653df2eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - [vars] no sv_detection_query_stop_words_removal, using empty str; 0 (\"Which cities have the most affordable housing\") {'dc_recognize_places': {}, 'llm_response': {'METRICS': ['affordable housing'], 'RANK': 'HIGH', 'SUB_PLACE_TYPE': 'CITY'}, 'main_place_inferred': None, 'original_query': 'Which cities have the most affordable housing', 'place_dcid_inference': 'Place DCID Inference did not trigger (no place strings found).', 'place_resolution': 'Place resolution did not trigger (no place dcids found).', 'places_found_str': [], 'query_transformations': {'sv_detection_query_index_types': ['']}} {'CosineScore': [], 'MultiSV': {}, 'Query': 'Which cities have the most affordable housing', 'SV': [], 'SV_to_Sentences': {}}\n",
            "WARNING - [api] NL API blocked request; 0 (\"incarceration rate by race in US\")\n",
            "WARNING - [api]  NL API request failed with status code 500; 0 (\"What is the impact of pollution on ocean life in Tulum\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[NlApiScrape(id=0, query='Which cities have the most affordable housing', dates=[], places=[], variables=[VariableResponse(search_label='', dcids=['Count_HousingUnit', 'Count_HousingUnit_OccupiedHousingUnit', 'Count_HousingUnit_VacantHousingUnit', 'Count_HousingUnit_HouseholderEducationalAttainmentBachelorsDegreeOrHigher_OccupiedHousingUnit', 'Count_HousingUnit_WithMortgage_OccupiedHousingUnit_OwnerOccupied', 'Count_Person_1OrMoreYears_RenterOccupied_ResidesInHousingUnit', 'Count_HousingUnit_OwnerOccupied'], per_capita=False, rank=None, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='incarceration rate by race in US', dates=[], places=[], variables=[], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=True),\n",
              " NlApiScrape(id=0, query='How much have gas prices increased in the US since 2000', dates=[], places=[DetectedPlace(dcid='country/USA', sub_place_type=None)], variables=[VariableResponse(search_label='gas prices', dcids=['Annual_Consumption_Fuel_CommerceAndPublicServices_MotorGasoline', 'Annual_Consumption_Fuel_RoadTransport_MotorGasoline', 'Annual_Consumption_Fuel_MotorGasoline', 'Annual_Consumption_Fuel_RoadTransport_NaturalGas', 'Annual_Consumption_Fuel_TransportIndustry_MotorGasoline', 'Annual_Consumption_Fuel_NaturalGas', 'Annual_Consumption_Fuel_RoadTransport_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_CommerceAndPublicServices_NaturalGas', 'Annual_Consumption_Fuel_Industry_NaturalGas_EnergyIndustryOwnUse', 'Annual_Consumption_Fuel_CommerceAndPublicServices_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_Agriculture_MotorGasoline', 'Annual_Consumption_Fuel_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_Households_NaturalGas', 'Annual_Consumption_Fuel_Manufacturing_MotorGasoline', 'Annual_Imports_Fuel_MotorGasoline', 'Annual_Consumption_Fuel_RoadTransport_BioGasoline', 'Annual_Consumption_Fuel_TransportIndustry_NaturalGas', 'Annual_Consumption_Fuel_TransportIndustry_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_BioGasoline', 'Annual_Consumption_Fuel_TransportIndustry_BioGasoline', 'Annual_Consumption_Fuel_TransportIndustry_AviationGasoline', 'Annual_Consumption_Fuel_Households_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_ChemicalPetrochemicalIndustry_NaturalGas', 'Mean_Inflation_EconomicActivity_ConsumerPriceIndex_FuelAndLightSector', 'Annual_Imports_Fuel_NaturalGas', 'Annual_Generation_Fuel_MotorGasoline', 'Annual_Loss_Fuel_NaturalGas', 'Annual_Consumption_Fuel_CommerceAndPublicServices_FuelOil', 'Annual_Consumption_Fuel_DomesticAviationTransport_AviationGasoline', 'Annual_Consumption_Fuel_ChemicalPetrochemicalIndustry_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_FoodAndTobaccoIndustry_NaturalGas', 'Annual_Imports_Fuel_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_TransportEquipmentIndustry_NaturalGas', 'Annual_Emissions_Methane_FossilFuelOperations', 'Annual_Consumption_Fuel_ConstructionIndustry_NaturalGas', 'Annual_Emissions_GreenhouseGas_OilAndGas', 'Annual_Consumption_Fuel_Agriculture_NaturalGas'], per_capita=False, rank=None, filter=None), VariableResponse(search_label='year', dcids=['Count_Person_ForeignBorn_PlaceOfBirthAfrica', 'Count_Person_PlaceOfBirthAsia', 'Count_Person_ForeignBorn_PlaceOfBirthCaribbean', 'Count_Person_ForeignBorn_PlaceOfBirthCentralAmericaExceptMexico', 'Count_Person_PlaceOfBirthEurope', 'Count_Person_ForeignBorn_PlaceOfBirthMexico', 'Count_Person_ForeignBorn_PlaceOfBirthNorthamerica', 'Count_Person_ForeignBorn_PlaceOfBirthOceania', 'Count_Person_ForeignBorn_PlaceOfBirthSouthamerica', 'Median_Age_Person_Female', 'Median_Age_Person_Male', 'Median_Age_Person', 'Count_Person_1To4Years', 'Count_Person_5To17Years', 'Count_Person_18To24Years', 'Count_Person_25To34Years', 'Count_Person_35To44Years', 'Count_Person_45To54Years', 'Count_Person_55To64Years', 'Count_Person_65To74Years', 'Count_Person_75OrMoreYears', 'Count_Person_85OrMoreYears_Female', 'Count_Person_85OrMoreYears_Male', 'Count_Person_0To4Years_Female', 'Count_Person_0To4Years_Male', 'Count_Person_FullTimeYearRoundWorker', 'Count_Death_AsAFractionOfCount_Person', 'Count_Death', 'Count_BirthEvent', 'Annual_Exports_Electricity', 'Amount_EconomicActivity_GrossDomesticProduction_Nominal', 'LifeExpectancy_Person'], per_capita=False, rank=None, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='List out counties with the worst AQI', dates=[], places=[DetectedPlace(dcid='', sub_place_type='COUNTY')], variables=[VariableResponse(search_label='AQI', dcids=['AirQualityIndex_AirPollutant_CO', 'AirQualityIndex_AirPollutant_NO2', 'AirQualityIndex_AirPollutant_Ozone', 'AirQualityIndex_AirPollutant_PM10', 'AirQualityIndex_AirPollutant_PM2.5', 'AirQualityIndex_AirPollutant_SO2', 'AirQualityIndex_AirPollutant'], per_capita=False, rank=<Ranking.HIGH: 'HIGH'>, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='I want to see stats about farming in Sonoma County', dates=[], places=[DetectedPlace(dcid='geoId/06097', sub_place_type=None)], variables=[VariableResponse(search_label='want see stats farming', dcids=['AmountFarmInventory_WinterWheatForGrain', 'Amount_FarmInventory_BarleyForGrain', 'Amount_FarmInventory_CornForSilageOrGreenchop', 'Amount_FarmInventory_Cotton', 'Amount_FarmInventory_DryEdibleBeans', 'Amount_FarmInventory_DurumWheatForGrain', 'Amount_FarmInventory_Forage', 'Amount_FarmInventory_OatsForGrain', 'Amount_FarmInventory_OtherSpringWheatForGrain', 'Amount_FarmInventory_PeanutsForNuts', 'Amount_FarmInventory_PimaCotton', 'Amount_FarmInventory_Rice', 'Amount_FarmInventory_SorghumForGrain', 'Amount_FarmInventory_SorghumForSilageOrGreenchop', 'Amount_FarmInventory_SugarbeetsForSugar', 'Amount_FarmInventory_SunflowerSeed', 'Amount_FarmInventory_UplandCotton', 'Amount_FarmInventory_WheatForGrain', 'Amount_FarmInventory_CornForGrain', 'Count_FarmInventory_BeefCows', 'Count_FarmInventory_Broilers', 'Count_FarmInventory_CattleAndCalves', 'Count_FarmInventory_HogsAndPigs', 'Count_FarmInventory_Layers', 'Count_FarmInventory_MilkCows', 'Count_FarmInventory_SheepAndLambs', 'Area_Farm', 'Count_Farm', 'Income_Farm', 'Count_Worker_NAICSAgricultureForestryFishingHunting'], per_capita=False, rank=None, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='Most common allergies in the US', dates=[], places=[DetectedPlace(dcid='country/USA', sub_place_type=None)], variables=[VariableResponse(search_label='common allergies', dcids=['Percent_Person_WithAsthma', 'Percent_Person_Children_WithAsthma', 'Percent_Person_WithArthritis', 'Percent_Person_WithAsthma', 'Percent_Person_WithCancerExcludingSkinCancer', 'Percent_Person_WithChronicKidneyDisease', 'Percent_Person_WithChronicObstructivePulmonaryDisease', 'Percent_Person_WithCoronaryHeartDisease', 'Percent_Person_WithDiabetes', 'Percent_Person_WithHighBloodPressure', 'Percent_Person_WithHighCholesterol', 'Percent_Person_WithMentalHealthNotGood', 'Percent_Person_WithPhysicalHealthNotGood', 'Percent_Person_WithStroke', 'Count_Person_Female_ConditionArthritis', 'Count_Person_Male_ConditionArthritis', 'Percent_Person_WithArthritis', 'Percent_Person_WithAsthma', 'Percent_Person_Children_WithAsthma', 'Percent_Person_WithHighBloodPressure', 'Percent_Person_18OrMoreYears_WithHighBloodPressure_ReceivedTakingBloodPressureMedication', 'Count_Death_Upto1Years_Neoplasms', 'Count_Death_1To4Years_Neoplasms', 'Count_Death_5To14Years_Neoplasms', 'Count_Death_15To24Years_Neoplasms', 'Count_Death_25To34Years_Neoplasms', 'Count_Death_35To44Years_Neoplasms', 'Count_Death_45To54Years_Neoplasms', 'Count_Death_55To64Years_Neoplasms', 'Count_Death_65To74Years_Neoplasms', 'Count_Death_75To84Years_Neoplasms', 'Count_Death_85Years_Neoplasms', 'Percent_Person_21To65Years_Female_ReceivedCervicalCancerScreening', 'Percent_Person_50To74Years_Female_ReceivedMammography', 'Percent_Person_50To75Years_ReceivedColorectalCancerScreening', 'Percent_Person_WithCancerExcludingSkinCancer', 'Count_Death_Neoplasms', 'Percent_Person_WithHighCholesterol', 'Percent_Person_ReceivedCholesterolScreening', 'Percent_Person_WithDiabetes', 'Count_Person_Female_ConditionDiseasesOfHeart', 'Count_Person_Male_ConditionDiseasesOfHeart', 'Percent_Person_WithCoronaryHeartDisease', 'Percent_Person_WithChronicObstructivePulmonaryDisease', 'Count_Death_15To24Years_MentalBehaviouralDisorders', 'Count_Death_25To34Years_MentalBehaviouralDisorders', 'Count_Death_35To44Years_MentalBehaviouralDisorders', 'Count_Death_45To54Years_MentalBehaviouralDisorders', 'Count_Death_55To64Years_MentalBehaviouralDisorders', 'Count_Death_65To74Years_MentalBehaviouralDisorders', 'Count_Death_75To84Years_MentalBehaviouralDisorders', 'Count_Death_85Years_MentalBehaviouralDisorders', 'Percent_Person_WithMentalHealthNotGood', 'Percent_Person_18OrMoreYears_WithDepression', 'Count_Death_MentalBehaviouralDisorders', 'Percent_Person_WithChronicKidneyDisease', 'Percent_Person_WithStroke', 'Count_MedicalConditionIncident_SummerSeason_ConditionHeatStress_PatientDeceased', 'Count_MedicalConditionIncident_SummerSeason_ConditionHeatStress_PatientHospitalized', 'Count_MedicalConditionIncident_SummerSeason_ConditionHeatStress_VisitedEmergencyDepartment'], per_capita=False, rank=<Ranking.HIGH: 'HIGH'>, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='Which countries have universal health care', dates=[], places=[DetectedPlace(dcid='', sub_place_type='COUNTRY')], variables=[VariableResponse(search_label='universal health care', dcids=['sdg/SH_ACS_UNHC', 'sdg/SH_XPD_EARN10', 'sdg/SH_XPD_EARN25', 'Count_Person_WithPrivateHealthInsurance', 'Count_Person_WithPrivateHealthInsuranceOnly', 'Count_Person_WithPublicHealthInsurance', 'Count_Person_WithPublicHealthInsuranceOnly', 'Count_Person_WithHealthInsurance', 'Count_Person_NoHealthInsurance', 'Count_Person_NoHealthInsurance', 'Percent_Person_WithArthritis', 'Percent_Person_WithAsthma', 'Percent_Person_WithCancerExcludingSkinCancer', 'Percent_Person_WithChronicKidneyDisease', 'Percent_Person_WithChronicObstructivePulmonaryDisease', 'Percent_Person_WithCoronaryHeartDisease', 'Percent_Person_WithDiabetes', 'Percent_Person_WithHighBloodPressure', 'Percent_Person_WithHighCholesterol', 'Percent_Person_WithMentalHealthNotGood', 'Percent_Person_WithPhysicalHealthNotGood', 'Percent_Person_WithStroke', 'Count_Person_Female_ConditionArthritis', 'Count_Person_Male_ConditionArthritis', 'Percent_Person_WithArthritis', 'Percent_Person_WithAsthma', 'Count_Person_WithDisability_Female', 'Count_Person_WithDisability_Male', 'Count_Person_WithDisability_AmericanIndianOrAlaskaNativeAlone', 'Count_Person_WithDisability_BlackOrAfricanAmericanAlone', 'Count_Person_WithDisability_HispanicOrLatino', 'Count_Person_WithDisability_OneRace', 'Count_Person_WithDisability_SomeOtherRaceAlone', 'Count_Person_WithDisability_TwoOrMoreRaces', 'Count_Person_WithDisability_WhiteAlone', 'Count_Person_WithDisability_WhiteAloneNotHispanicOrLatino', 'Count_Person_Female_NoHealthInsurance', 'Count_Person_Male_NoHealthInsurance', 'Count_Person_Female_WithHealthInsurance', 'Count_Person_Male_WithHealthInsurance', 'Count_Person_WithPrivateHealthInsurance', 'Count_Person_WithPrivateHealthInsuranceOnly', 'Count_Person_WithPublicHealthInsurance', 'Count_Person_WithPublicHealthInsuranceOnly', 'Count_Person_WithHealthInsurance', 'Count_Person_NoHealthInsurance', 'Count_Person_NoHealthInsurance', 'LifeExpectancy_Person_Female', 'LifeExpectancy_Person_Male', 'Count_Death', 'Count_Death_AsAFractionOfCount_Person', 'LifeExpectancy_Person', 'Percent_Person_BingeDrinking', 'Percent_Person_Obesity', 'Percent_Person_PhysicalInactivity', 'Percent_Person_SleepLessThan7Hours', 'Percent_Person_Smoking', 'Percent_Person_21To65Years_Female_ReceivedCervicalCancerScreening', 'Percent_Person_50To75Years_ReceivedColorectalCancerScreening', 'Percent_Person_ReceivedCholesterolScreening', 'Percent_Person_ReceivedDentalVisit', 'Percent_Person_ReceivedAnnualCheckup', 'WHO/Adult_daily_tob_use', 'WHO/M_Est_smk_daily', 'WHO/NCD_BMI_18A', 'WHO/NCD_BMI_30A', 'WHO/NCD_PAC', 'WHO/WHS4_117', 'WHO/WHS4_128', 'WHO/WHS4_129', 'Count_Person_WithDisability_Female', 'Count_Person_WithDisability_Male', 'Count_Person_WithDisability_AmericanIndianOrAlaskaNativeAlone', 'Count_Person_WithDisability_BlackOrAfricanAmericanAlone', 'Count_Person_WithDisability_HispanicOrLatino', 'Count_Person_WithDisability_OneRace', 'Count_Person_WithDisability_SomeOtherRaceAlone', 'Count_Person_WithDisability_TwoOrMoreRaces', 'Count_Person_WithDisability_WhiteAlone', 'Count_Person_WithDisability_WhiteAloneNotHispanicOrLatino', 'Count_Person_Female_NoHealthInsurance', 'Count_Person_Male_NoHealthInsurance', 'Count_Person_Female_WithHealthInsurance', 'Count_Person_Male_WithHealthInsurance', 'sdg/SH_ACS_UNHC', 'WHO/Adult_daily_tob_use', 'WHO/M_Est_smk_daily', 'WHO/NCD_BMI_18A', 'WHO/NCD_BMI_30A', 'WHO/NCD_PAC', 'WHO/WHS4_117', 'WHO/WHS4_128', 'WHO/WHS4_129', 'Count_Person_WithHealthInsurance', 'Percent_Person_WithArthritis', 'Percent_Person_WithAsthma', 'Percent_Person_WithCancerExcludingSkinCancer', 'Percent_Person_WithChronicKidneyDisease', 'Percent_Person_WithChronicObstructivePulmonaryDisease', 'Percent_Person_WithCoronaryHeartDisease', 'Percent_Person_WithDiabetes', 'Percent_Person_WithHighBloodPressure', 'Percent_Person_WithHighCholesterol', 'Percent_Person_WithMentalHealthNotGood', 'Percent_Person_WithPhysicalHealthNotGood', 'Percent_Person_WithStroke', 'Count_Person_Female_ConditionArthritis', 'Count_Person_Male_ConditionArthritis', 'Percent_Person_WithArthritis', 'Percent_Person_WithAsthma', 'Count_Person_Female_NoHealthInsurance', 'Count_Person_Male_NoHealthInsurance', 'Count_Person_16OrMoreYears_NoHealthInsurance_IncomeOf4999OrLessUSDollar_WithEarnings', 'Count_Person_16OrMoreYears_NoHealthInsurance_IncomeOf5000To14999USDollar_WithEarnings', 'Count_Person_16OrMoreYears_NoHealthInsurance_IncomeOf15000To24999USDollar_WithEarnings', 'Count_Person_16OrMoreYears_NoHealthInsurance_IncomeOf25000To34999USDollar_WithEarnings', 'Count_Person_16OrMoreYears_NoHealthInsurance_IncomeOf35000To49999USDollar_WithEarnings', 'Count_Person_16OrMoreYears_NoHealthInsurance_IncomeOf50000To74999USDollar_WithEarnings', 'Count_Person_16OrMoreYears_NoHealthInsurance_IncomeOf75000OrMoreUSDollar_WithEarnings', 'Count_Person_NoHealthInsurance_WhiteAlone', 'Count_Person_NoHealthInsurance_BlackOrAfricanAmericanAlone', 'Count_Person_NoHealthInsurance_HispanicOrLatino', 'Count_Person_NoHealthInsurance_AsianAlone', 'Count_Person_NoHealthInsurance_AmericanIndianOrAlaskaNativeAlone', 'Count_Person_NoHealthInsurance_NativeHawaiianOrOtherPacificIslanderAlone', 'Count_Person_NoHealthInsurance', 'Amount_EconomicActivity_ExpenditureActivity_HealthcareExpenditure_AsFractionOf_Count_Person', 'USStateQuarterlyIndustryGDP_NAICS_62', 'Count_Person_NoHealthInsurance', 'Count_Person_WithPrivateHealthInsurance', 'Count_Person_WithPrivateHealthInsuranceOnly', 'Count_Person_WithPublicHealthInsurance', 'Count_Person_WithPublicHealthInsuranceOnly', 'Count_Person_WithPublicHealthInsurance', 'Amount_EconomicActivity_GrossDomesticProduction_NAICSHealthCareSocialAssistance_RealValue', 'Count_Establishment_NAICSHealthCareSocialAssistance', 'dc/tz59wt1hkl4y'], per_capita=False, rank=None, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='What is the impact of pollution on ocean life in Tulum', dates=[], places=[], variables=[], scrape_date='2025-09-22', api_response_status=<ResponseStatus.ERROR: 'ERROR'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='Areas with the highest crime rate', dates=[], places=[], variables=[VariableResponse(search_label='crime rate', dcids=['Count_CriminalActivities_AggravatedAssault', 'Count_CriminalActivities_Arson', 'Count_CriminalActivities_Burglary', 'Count_CriminalActivities_ForcibleRape', 'Count_CriminalActivities_LarcenyTheft', 'Count_CriminalActivities_MotorVehicleTheft', 'Count_CriminalActivities_PropertyCrime', 'Count_CriminalActivities_Robbery', 'Count_CriminalActivities_ViolentCrime', 'Count_CriminalActivities_CombinedCrime', 'Count_CriminalActivities_MurderAndNonNegligentManslaughter_AsFractionOf_Count_Person', 'Count_CriminalActivities_CombinedCrime', 'Count_CriminalActivities_ViolentCrime', 'Count_CriminalActivities_PropertyCrime', 'Count_CriminalIncidents', 'Count_CriminalActivities_Burglary', 'Count_CriminalActivities_MurderAndNonNegligentManslaughter_AsFractionOf_Count_Person', 'Count_CriminalActivities_Robbery', 'Count_CriminalActivities_MurderAndNonNegligentManslaughter', 'Count_CriminalActivities_LarcenyTheft', 'Count_CriminalActivities_MotorVehicleTheft', 'Count_CriminalIncidents_IsHateCrime'], per_capita=False, rank=<Ranking.HIGH: 'HIGH'>, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='How much have gas prices increased in the US since 2000', dates=[], places=[DetectedPlace(dcid='country/USA', sub_place_type=None)], variables=[VariableResponse(search_label='gas prices', dcids=['Annual_Consumption_Fuel_CommerceAndPublicServices_MotorGasoline', 'Annual_Consumption_Fuel_RoadTransport_MotorGasoline', 'Annual_Consumption_Fuel_MotorGasoline', 'Annual_Consumption_Fuel_RoadTransport_NaturalGas', 'Annual_Consumption_Fuel_TransportIndustry_MotorGasoline', 'Annual_Consumption_Fuel_NaturalGas', 'Annual_Consumption_Fuel_RoadTransport_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_CommerceAndPublicServices_NaturalGas', 'Annual_Consumption_Fuel_Industry_NaturalGas_EnergyIndustryOwnUse', 'Annual_Consumption_Fuel_CommerceAndPublicServices_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_Agriculture_MotorGasoline', 'Annual_Consumption_Fuel_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_Households_NaturalGas', 'Annual_Consumption_Fuel_Manufacturing_MotorGasoline', 'Annual_Imports_Fuel_MotorGasoline', 'Annual_Consumption_Fuel_RoadTransport_BioGasoline', 'Annual_Consumption_Fuel_TransportIndustry_NaturalGas', 'Annual_Consumption_Fuel_TransportIndustry_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_BioGasoline', 'Annual_Consumption_Fuel_TransportIndustry_BioGasoline', 'Annual_Consumption_Fuel_TransportIndustry_AviationGasoline', 'Annual_Consumption_Fuel_Households_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_ChemicalPetrochemicalIndustry_NaturalGas', 'Mean_Inflation_EconomicActivity_ConsumerPriceIndex_FuelAndLightSector', 'Annual_Imports_Fuel_NaturalGas', 'Annual_Generation_Fuel_MotorGasoline', 'Annual_Loss_Fuel_NaturalGas', 'Annual_Consumption_Fuel_CommerceAndPublicServices_FuelOil', 'Annual_Consumption_Fuel_DomesticAviationTransport_AviationGasoline', 'Annual_Consumption_Fuel_ChemicalPetrochemicalIndustry_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_FoodAndTobaccoIndustry_NaturalGas', 'Annual_Imports_Fuel_LiquifiedPetroleumGas', 'Annual_Consumption_Fuel_TransportEquipmentIndustry_NaturalGas', 'Annual_Emissions_Methane_FossilFuelOperations', 'Annual_Consumption_Fuel_ConstructionIndustry_NaturalGas', 'Annual_Emissions_GreenhouseGas_OilAndGas', 'Annual_Consumption_Fuel_Agriculture_NaturalGas'], per_capita=False, rank=None, filter=None), VariableResponse(search_label='year', dcids=['Count_Person_ForeignBorn_PlaceOfBirthAfrica', 'Count_Person_PlaceOfBirthAsia', 'Count_Person_ForeignBorn_PlaceOfBirthCaribbean', 'Count_Person_ForeignBorn_PlaceOfBirthCentralAmericaExceptMexico', 'Count_Person_PlaceOfBirthEurope', 'Count_Person_ForeignBorn_PlaceOfBirthMexico', 'Count_Person_ForeignBorn_PlaceOfBirthNorthamerica', 'Count_Person_ForeignBorn_PlaceOfBirthOceania', 'Count_Person_ForeignBorn_PlaceOfBirthSouthamerica', 'Median_Age_Person_Female', 'Median_Age_Person_Male', 'Median_Age_Person', 'Count_Person_1To4Years', 'Count_Person_5To17Years', 'Count_Person_18To24Years', 'Count_Person_25To34Years', 'Count_Person_35To44Years', 'Count_Person_45To54Years', 'Count_Person_55To64Years', 'Count_Person_65To74Years', 'Count_Person_75OrMoreYears', 'Count_Person_85OrMoreYears_Female', 'Count_Person_85OrMoreYears_Male', 'Count_Person_0To4Years_Female', 'Count_Person_0To4Years_Male', 'Count_Person_FullTimeYearRoundWorker', 'Count_Death_AsAFractionOfCount_Person', 'Count_Death', 'Count_BirthEvent', 'Annual_Exports_Electricity', 'Amount_EconomicActivity_GrossDomesticProduction_Nominal', 'LifeExpectancy_Person'], per_capita=False, rank=None, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False),\n",
              " NlApiScrape(id=0, query='Population of the us', dates=[], places=[DetectedPlace(dcid='country/USA', sub_place_type=None)], variables=[VariableResponse(search_label='population', dcids=['Count_Person', 'IncrementalCount_Person', 'Count_Person_PerArea', 'Median_Age_Person_Female', 'Median_Age_Person_Male', 'Count_Person_1To4Years', 'Count_Person_5To17Years', 'Count_Person_18To24Years', 'Count_Person_25To34Years', 'Count_Person_35To44Years', 'Count_Person_45To54Years', 'Count_Person_55To64Years', 'Count_Person_65To74Years', 'Count_Person_75OrMoreYears', 'Count_Person_85OrMoreYears_Female', 'Count_Person_85OrMoreYears_Male', 'Median_Age_Person', 'Count_Person_Female', 'Count_Person_Male', 'Count_Person_WhiteAlone', 'Count_Person_BlackOrAfricanAmericanAlone', 'Count_Person_HispanicOrLatino', 'Count_Person_AsianAlone', 'Count_Person_AmericanIndianAndAlaskaNativeAlone', 'Count_Person_AsianOrPacificIslander', 'Count_Person_NativeHawaiianOrOtherPacificIslanderAlone', 'Count_Person_SomeOtherRaceAlone', 'Count_Person_AmericanIndianAndAlaskaNativeAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_AsianAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_BlackOrAfricanAmericanAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NativeHawaiianAndOtherPacificIslanderAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_WhiteAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_HispanicOrLatino_AmericanIndianOrAlaskaNativeAlone', 'Count_Person_HispanicOrLatino_AsianAlone', 'Count_Person_HispanicOrLatino_AsianOrPacificIslander', 'Count_Person_HispanicOrLatino_BlackOrAfricanAmericanAlone', 'Count_Person_HispanicOrLatino_NativeHawaiianOrOtherPacificIslanderAlone', 'Count_Person_HispanicOrLatino_TwoOrMoreRaces', 'Count_Person_HispanicOrLatino_WhiteAlone', 'Count_Person_HispanicOrLatino_AmericanIndianAndAlaskaNativeAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_HispanicOrLatino_AsianAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_HispanicOrLatino_NativeHawaiianAndOtherPacificIslanderAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_HispanicOrLatino_WhiteAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_WhiteAloneNotHispanicOrLatino', 'Count_Person_NotHispanicOrLatino_AmericanIndianOrAlaskaNativeAlone', 'Count_Person_NotHispanicOrLatino_AsianAlone', 'Count_Person_NotHispanicOrLatino_AsianOrPacificIslander', 'Count_Person_NotHispanicOrLatino_BlackOrAfricanAmericanAlone', 'Count_Person_NotHispanicOrLatino_NativeHawaiianOrOtherPacificIslanderAlone', 'Count_Person_NotHispanicOrLatino_AmericanIndianAndAlaskaNativeAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NotHispanicOrLatino_AsianAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NotHispanicOrLatino_BlackOrAfricanAmericanAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NotHispanicOrLatino_NativeHawaiianAndOtherPacificIslanderAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NotHispanicOrLatino_TwoOrMoreRaces', 'Count_Person_NotHispanicOrLatino_WhiteAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_5OrMoreYears_OnlyEnglishSpokenAtHome', 'Count_Person_5OrMoreYears_LanguageOtherThanEnglishSpokenAtHome', 'Count_Person_5OrMoreYears_AfricanLanguagesSpokenAtHome', 'Count_Person_5OrMoreYears_ArabicSpokenAtHome', 'Count_Person_5OrMoreYears_ArmenianSpokenAtHome', 'Count_Person_5OrMoreYears_BengaliSpokenAtHome', 'Count_Person_5OrMoreYears_ChineseSpokenAtHome', 'Count_Person_5OrMoreYears_FrenchInclPatoisCajunSpokenAtHome', 'Count_Person_5OrMoreYears_GermanSpokenAtHome', 'Count_Person_5OrMoreYears_GreekSpokenAtHome', 'Count_Person_5OrMoreYears_GujaratiSpokenAtHome', 'Count_Person_5OrMoreYears_HaitianSpokenAtHome', 'Count_Person_5OrMoreYears_HebrewSpokenAtHome', 'Count_Person_5OrMoreYears_HindiSpokenAtHome', 'Count_Person_5OrMoreYears_HungarianSpokenAtHome', 'Count_Person_5OrMoreYears_ItalianSpokenAtHome', 'Count_Person_5OrMoreYears_JapaneseSpokenAtHome', 'Count_Person_5OrMoreYears_KhmerSpokenAtHome', 'Count_Person_5OrMoreYears_KoreanSpokenAtHome', 'Count_Person_5OrMoreYears_LaotianSpokenAtHome', 'Count_Person_5OrMoreYears_MalayalamKannadaOrOtherDravidianLanguagesSpokenAtHome', 'Count_Person_5OrMoreYears_MonKhmerCambodianSpokenAtHome', 'Count_Person_5OrMoreYears_NavajoSpokenAtHome', 'Count_Person_5OrMoreYears_NepaliMarathiOrOtherIndicLanguagesSpokenAtHome', 'Count_Person_5OrMoreYears_PersianSpokenAtHome', 'Count_Person_5OrMoreYears_PolishSpokenAtHome', 'Count_Person_5OrMoreYears_PortugueseSpokenAtHome', 'Count_Person_5OrMoreYears_PunjabiSpokenAtHome', 'Count_Person_5OrMoreYears_RussianSpokenAtHome', 'Count_Person_5OrMoreYears_ScandinavianLanguagesSpokenAtHome', 'Count_Person_5OrMoreYears_SerboCroatianSpokenAtHome', 'Count_Person_5OrMoreYears_SpanishSpokenAtHome', 'Count_Person_5OrMoreYears_TagalogSpokenAtHome', 'Count_Person_5OrMoreYears_TamilSpokenAtHome', 'Count_Person_5OrMoreYears_TeluguSpokenAtHome', 'Count_Person_5OrMoreYears_ThaiSpokenAtHome', 'Count_Person_5OrMoreYears_UkrainianOrOtherSlavicLanguagesSpokenAtHome', 'Count_Person_5OrMoreYears_UrduSpokenAtHome', 'Count_Person_5OrMoreYears_VietnameseSpokenAtHome', 'Count_Person_5OrMoreYears_YiddishSpokenAtHome', 'Count_Person_Divorced', 'Count_Person_MarriedAndNotSeparated', 'Count_Person_NeverMarried', 'Count_Person_Widowed', 'Count_Person_Female_Divorced', 'Count_Person_Male_Divorced', 'Count_Person_15OrMoreYears_Divorced_AsianAlone', 'Count_Person_15OrMoreYears_Divorced_BlackOrAfricanAmericanAlone', 'Count_Person_15OrMoreYears_Divorced_HispanicOrLatino', 'Count_Person_Divorced', 'Count_Person_ForeignBorn', 'Count_Person_Native', 'Count_Person_ForeignBorn_PlaceOfBirthAfrica', 'Count_Person_PlaceOfBirthAsia', 'Count_Person_ForeignBorn_PlaceOfBirthCaribbean', 'Count_Person_ForeignBorn_PlaceOfBirthCentralAmericaExceptMexico', 'Count_Person_PlaceOfBirthEurope', 'Count_Person_ForeignBorn_PlaceOfBirthMexico', 'Count_Person_ForeignBorn_PlaceOfBirthNorthamerica', 'Count_Person_ForeignBorn_PlaceOfBirthOceania', 'Count_Person_ForeignBorn_PlaceOfBirthSouthamerica', 'Count_Person_5OrMoreYears_OnlyEnglishSpokenAtHome_ForeignBorn', 'Count_Person_5OrMoreYears_SpanishSpokenAtHome_ForeignBorn', 'dc/21j845ny0gpl6', 'dc/xg4bepzr1wb93', 'dc/ll54s8y2d720d', 'dc/wpkqjslkwknbc', 'dc/2d5rby4n8sf38', 'dc/y1gfw4jel63s3', 'dc/747gqczgzpcqd', 'dc/krq9b63v51kmh', 'dc/jk91lheqelvm3', 'dc/j4jtrsnn9n2dc', 'dc/e783knv4pn079', 'dc/dlp5xgcwee7yb', 'dc/cc71n5d28t8m6', 'dc/wnecwy4tfcr17', 'dc/k7dlecx0l0zn8', 'dc/b2l0jcm65s4x2', 'dc/4n1l2j3e2wy7f', 'Count_Person_Veteran', 'dc/ec13z1eh1d5d8', 'Count_Person', 'Count_Person_PerArea', 'GrowthRate_Count_Person', 'Count_Person_18OrMoreYears', 'Count_Person_Upto18Years', 'Count_BirthEvent', 'Count_Person_IncomeOfUpto9999USDollar', 'Count_Person_IncomeOf10000To14999USDollar', 'Count_Person_IncomeOf25000To34999USDollar', 'Count_Person_IncomeOf35000To49999USDollar', 'Count_Person_IncomeOf50000To64999USDollar', 'Count_Person_IncomeOf65000To74999USDollar', 'Count_Person_IncomeOf75000OrMoreUSDollar', 'GrowthRate_Count_Person', 'Count_Person_WhiteAlone', 'Count_Person_BlackOrAfricanAmericanAlone', 'Count_Person_HispanicOrLatino', 'Count_Person_AsianAlone', 'Count_Person_AmericanIndianAndAlaskaNativeAlone', 'Count_Person_AsianOrPacificIslander', 'Count_Person_NativeHawaiianOrOtherPacificIslanderAlone', 'Count_Person_SomeOtherRaceAlone', 'Count_Person_AmericanIndianAndAlaskaNativeAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_AsianAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_BlackOrAfricanAmericanAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NativeHawaiianAndOtherPacificIslanderAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_WhiteAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_HispanicOrLatino_AmericanIndianOrAlaskaNativeAlone', 'Count_Person_HispanicOrLatino_AsianAlone', 'Count_Person_HispanicOrLatino_AsianOrPacificIslander', 'Count_Person_HispanicOrLatino_BlackOrAfricanAmericanAlone', 'Count_Person_HispanicOrLatino_NativeHawaiianOrOtherPacificIslanderAlone', 'Count_Person_HispanicOrLatino_TwoOrMoreRaces', 'Count_Person_HispanicOrLatino_WhiteAlone', 'Count_Person_HispanicOrLatino_AmericanIndianAndAlaskaNativeAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_HispanicOrLatino_AsianAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_HispanicOrLatino_NativeHawaiianAndOtherPacificIslanderAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_HispanicOrLatino_WhiteAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_WhiteAloneNotHispanicOrLatino', 'Count_Person_NotHispanicOrLatino_AmericanIndianOrAlaskaNativeAlone', 'Count_Person_NotHispanicOrLatino_AsianAlone', 'Count_Person_NotHispanicOrLatino_AsianOrPacificIslander', 'Count_Person_NotHispanicOrLatino_BlackOrAfricanAmericanAlone', 'Count_Person_NotHispanicOrLatino_NativeHawaiianOrOtherPacificIslanderAlone', 'Count_Person_NotHispanicOrLatino_AmericanIndianAndAlaskaNativeAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NotHispanicOrLatino_AsianAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NotHispanicOrLatino_BlackOrAfricanAmericanAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NotHispanicOrLatino_NativeHawaiianAndOtherPacificIslanderAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_Person_NotHispanicOrLatino_TwoOrMoreRaces', 'Count_Person_NotHispanicOrLatino_WhiteAloneOrInCombinationWithOneOrMoreOtherRaces', 'Count_BirthEvent_AsAFractionOfCount_Person', 'Count_Person_Urban', 'Count_BirthEvent_LiveBirth', 'Count_BirthEvent_LiveBirth_AsFractionOf_Count_Person', 'Count_Person_Native', 'Count_Person_Female', 'Count_Person_Male', 'FertilityRate_Person_Female', 'Count_Person_Employed', 'dc/nm9hcklgg5zb3', 'Count_Person_MarriedAndNotSeparated', 'Count_Household', 'Count_Person_Rural', 'Count_Person_InLaborForce', 'Count_Person_ResidesInHousehold', 'Count_Household_Urban', 'Count_Death', 'Count_Person_15OrMoreYears_MarriedAndNotSeparated_Native', 'Count_Person_5OrMoreYears_ResidesInHousehold', 'Count_Person_Literate'], per_capita=False, rank=None, filter=None)], scrape_date='2025-09-22', api_response_status=<ResponseStatus.OK: 'OK'>, api_blocked=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "watch_list = [\n",
        "    \"Which cities have the most affordable housing\",\n",
        "    \"incarceration rate by race in US\",\n",
        "    \"How much have gas prices increased in the US since 2000\",\n",
        "              \"List out counties with the worst AQI\",\n",
        "              \"I want to see stats about farming in Sonoma County\",\n",
        "              \"Most common allergies in the US\",\n",
        "              \"Which countries have universal health care\",\n",
        "              \"What is the impact of pollution on ocean life in Tulum\",\n",
        "              \"Areas with the highest crime rate\",\n",
        "    \"How much have gas prices increased in the US since 2000\",\n",
        "    \"Population of the us\"]\n",
        "scrapes = []\n",
        "for query in watch_list:\n",
        "  s = scrape_query(0, query)\n",
        "  scrapes.append(s)\n",
        "scrapes"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3IrmNK5yFZbO",
        "s66Mq36Elur3",
        "2fVVnDkcxUCH"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
