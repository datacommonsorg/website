# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Homegrown Place Recognition implementation."""

import copy
import csv
from dataclasses import dataclass
import logging
import os
from typing import Dict, List

import nl_server.gcs as gcs

# This was generated by http://gpaste/5529122603270144
_PLACE_OBJECT = 'USGeosForPlaceRecognition.csv'
_MAX_PLACE_CANDIDATES = 3

#
# This is a home-grown implementation of place recognition by Guha.
# It is currently in an early version which will eventually move
# to the Mixer.
#


# word --> [[remaining words], dcid, [containing places dcid]] ...]
@dataclass
class Place:
  words: str
  dcid: str
  containing_places: List[str]
  population: int


@dataclass
class TokenSpan:
  tokens: List[str]
  places: List[Place]


class DcPlaceRecognition:

  def __init__(self):
    self.places: Dict[str, Place] = {}

    downloaded_file = gcs.download(_PLACE_OBJECT)
    with open(downloaded_file) as fp:
      reader = csv.DictReader(fp)
      for row in reader:
        containing = row['linkedContainedInPlace'].strip().split(',')
        # Make the names lower and add.
        nameParts = row['name'].strip().lower().split(' ')
        population = int(row['population'])
        if nameParts[0] not in self.places:
          self.places[nameParts[0]] = []
        self.places[nameParts[0]].append(
            Place(words=nameParts,
                  dcid=row['dcid'],
                  containing_places=containing,
                  population=population))

  def detect_places(self, query: str):
    toks = self._replace_tokens_with_candidates(_tokenize(query))
    candidates = _combine_contained_in(toks)
    filtered_candidates = _rank_and_trim(candidates)
    return _prepare_response(filtered_candidates)

  def _find_place_cand(self, tokens):
    if (len(tokens) == 0):
      return None
    next = tokens[0].lower()
    if (next not in self.places):
      return [0, None]
    places = self.places[next]
    numTokens = 1
    candidates = []
    for cand in places:
      n = 0
      notFound = False
      for w in cand.words:
        if ((len(tokens) <= n) or (w != tokens[n].lower())):
          notFound = True
          break
        n = n + 1
      if (numTokens < n):
        numTokens = n
      if (not notFound):
        # Make a deep copy since we may mutate the candidates.
        candidates.append(copy.deepcopy(cand))
    return [numTokens, candidates]

  def _replace_tokens_with_candidates(self,
                                      tokens: List[str]) -> List[TokenSpan]:
    ans = []
    while (len(tokens) > 0):
      next = self._find_place_cand(tokens)
      if (next[0] > 0):
        matched_tokens = tokens[0:next[0]]
        ans.append(TokenSpan(tokens=matched_tokens, places=next[1]))
        tokens = tokens[next[0]:]
      else:
        ans.append(TokenSpan(tokens=tokens[0:1], places=[]))
        tokens = tokens[1:]
    return ans


def _prepare_response(candidates: List[TokenSpan]) -> Dict:
  ans = []
  span_parts = []
  for c in candidates:
    part = ' '.join(c.tokens)
    if c.places:
      if span_parts:
        ans.append({'span': ' '.join(span_parts)})
        span_parts = []

      ans.append({'span': part, 'places': [p.dcid for p in c.places]})
    else:
      span_parts.append(part)

  if span_parts:
    ans.append({'span': ' '.join(span_parts)})

  return ans


def _tokenize(str: str) -> List[str]:
  ans = []
  n = 0
  inSpace = False
  nextStr = []
  while (n < len(str)):
    nc = str[n]
    if (nc == ' '):
      inSpace = True
      if (len(nextStr) > 0):
        ans.append("".join(nextStr))
        nextStr = []
    elif (nc == ','):
      inSpace == True
      if (len(nextStr) > 0):
        ans.append("".join(nextStr))
        ans.append(',')
        nextStr = []
    else:
      nextStr.append(nc)
    n = n + 1
  if (len(nextStr) > 0):
    ans.append("".join(nextStr))
  return ans


def _get_num_toks_for_contained_in(seq: List[TokenSpan], n: int) -> int:
  if (len(seq) > n + 2 and seq[n + 1].tokens == [','] and seq[n + 2].places):
    return 3
  elif (len(seq) > n + 1 and seq[n + 1].places):
    return 2
  else:
    return 0


def _combine_contained_in(seq: List[TokenSpan]) -> List[TokenSpan]:
  n = 0
  ans = []
  while (n < len(seq)):
    tok = seq[n]
    if not tok.places:
      n = n + 1
      ans.append(tok)
      continue
    numTok = _get_num_toks_for_contained_in(seq, n)
    if (numTok == 0):
      n = n + 1
      ans.append(tok)
      continue
    collapsed = _combine_contained_in_int(seq, n, numTok)
    if (not collapsed):
      n = n + 1
      ans.append(tok)
    else:
      n = n + numTok
      ans.append(collapsed)
  return ans


def _combine_contained_in_int(seq: List[TokenSpan], n: int,
                              numTok: int) -> TokenSpan:
  stok = seq[n]
  etok = seq[n + numTok - 1]
  for p1 in stok.places:
    for containingDcid in p1.containing_places:
      for p2 in etok.places:
        if (containingDcid == p2.dcid):
          ans = stok
          for i in range(1, numTok):
            ans.tokens.extend(seq[n + i].tokens)
            ans.places.extend(seq[n + i].places)
          return ans
  return None


def _rank_and_trim_places(tok: TokenSpan):
  # Rank by descending population
  tok.places.sort(key=lambda p: p.population, reverse=True)
  tok.places = tok.places[:_MAX_PLACE_CANDIDATES]
  return tok


def _rank_and_trim(candidates: List[TokenSpan]) -> List[TokenSpan]:
  ans = []
  for tok in candidates:
    if not tok.places:
      ans.append(tok)
      continue
    ans.append(_rank_and_trim_places(tok))
  return ans
